This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
data.yaml/accident_ran(not_used).yaml
data.yaml/climber.yaml
data.yaml/cracks_dents.yaml
data.yaml/fights_detection(not_used).yaml
data.yaml/fights_gisc.yaml
data.yaml/fire_smoke.yaml
data.yaml/fire_smoke(not used).yaml
data.yaml/guns_knives.yaml
data.yaml/realtime_accidnt.yaml
download_images.py
models_results/detect/climbing/args.yaml
models_results/detect/climbing/results.csv
models_results/detect/cracks_dents/args.yaml
models_results/detect/cracks_dents/results.csv
models_results/detect/fights/args.yaml
models_results/detect/fights/results.csv
models_results/detect/fire_smoke_new/args.yaml
models_results/detect/fire_smoke_new/results.csv
models_results/detect/fire_smoke_prev(not_used)/args.yaml
models_results/detect/fire_smoke_prev(not_used)/results.csv
models_results/detect/guns_knives/args.yaml
models_results/detect/guns_knives/results.csv
models_results/detect/realtime_accident/args.yaml
models_results/detect/realtime_accident/results.csv
predictions.py
requirements.txt
temp.py
training_code/models_training_code_new.ipynb
training_code/requirements.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="data.yaml/accident_ran(not_used).yaml">
names:
- bike
- bike_bike_accident
- bike_object_accident
- bike_person_accident
- car
- car_bike_accident
- car_car_accident
- car_object_accident
- car_person_accident
- person
nc: 10
roboflow:
  license: CC BY 4.0
  project: accidetect-a9uvo
  url: https://universe.roboflow.com/abc-llt0y/accidetect-a9uvo/dataset/3
  version: 3
  workspace: abc-llt0y
test: ../test/images
train: ../AcciDetect-3/train/images
val: ../AcciDetect-3/valid/images
</file>

<file path="data.yaml/climber.yaml">
names:
- climbing
nc: 1
roboflow:
  license: CC BY 4.0
  project: climbing-detection
  url: https://universe.roboflow.com/min-tang-ugcdi/climbing-detection/dataset/1
  version: 1
  workspace: min-tang-ugcdi
test: ../climbing-detection-1/test/images
train: ../climbing-detection-1/train/images
val: ../climbing-detection-1/valid/images
</file>

<file path="data.yaml/cracks_dents.yaml">
names:
- crack
nc: 1
roboflow:
  license: CC BY 4.0
  project: crack-detection-ypnwo
  url: https://universe.roboflow.com/ta-8behn/crack-detection-ypnwo/dataset/2
  version: 2
  workspace: ta-8behn
test: ../Crack-Detection-2/test/images
train: ../Crack-Detection-2/train/images
val: ../Crack-Detection-2/valid/images
</file>

<file path="data.yaml/fights_detection(not_used).yaml">
names:
- fight
nc: 1
roboflow:
  license: MIT
  project: sight-fight-detection
  url: https://universe.roboflow.com/sight/sight-fight-detection/dataset/1
  version: 1
  workspace: sight
test: ../SIGHT-Fight-Detection-1/test/images
train: ../SIGHT-Fight-Detection-1/train/images
val: ../SIGHT-Fight-Detection-1/valid/images
</file>

<file path="data.yaml/fights_gisc.yaml">
names:
- fight
nc: 1
roboflow:
  license: CC BY 4.0
  project: gisc
  url: https://universe.roboflow.com/mslee/gisc/dataset/1
  version: 1
  workspace: mslee
test: ../gisc-1/test/images
train: ../gisc-1/train/images
val: ../gisc-1/valid/images
</file>

<file path="data.yaml/fire_smoke.yaml">
names:
- fire
- smoke
nc: 2
roboflow:
  license: CC BY 4.0
  project: firesmoke-qedaj
  url: https://universe.roboflow.com/gradproject-b3qu8/firesmoke-qedaj/dataset/5
  version: 5
  workspace: gradproject-b3qu8
test: ../firesmoke-3/test/images
train: ../firesmoke-3/train/images
val: ../firesmoke-3/valid/images
</file>

<file path="data.yaml/fire_smoke(not used).yaml">
names:
- fire
- other
- smoke
nc: 3
roboflow:
  license: CC BY 4.0
  project: fire-smoke-detection-odvk6
  url: https://universe.roboflow.com/my-space-3zzwr/fire-smoke-detection-odvk6/dataset/1
  version: 1
  workspace: my-space-3zzwr
test: ../Fire-Smoke-Detection-1/test/images
train: ../Fire-Smoke-Detection-1/train/images
val: ../Fire-Smoke-Detection-1/valid/images
</file>

<file path="data.yaml/guns_knives.yaml">
names:
- gun
- knife
nc: 2
roboflow:
  license: CC BY 4.0
  project: guns_n_knives-h4bky
  url: https://universe.roboflow.com/crime-detection/guns_n_knives-h4bky/dataset/3
  version: 3
  workspace: crime-detection
test: ../test/images
train: ../guns_n_knives-3/train/images
val: ../guns_n_knives-3/valid/images
</file>

<file path="data.yaml/realtime_accidnt.yaml">
names:
- bike
- bike_bike_accident
- bike_object_accident
- bike_person_accident
- car
- car_bike_accident
- car_car_accident
- car_object_accident
- car_person_accident
- person
nc: 10
roboflow:
  license: CC BY 4.0
  project: real-time-accident-detection
  url: https://universe.roboflow.com/puyush-fipgg/real-time-accident-detection/dataset/1
  version: 1
  workspace: puyush-fipgg
test: ../Real-Time-Accident-Detection-1/test/images
train: ../Real-Time-Accident-Detection-1/train/images
val: ../Real-Time-Accident-Detection-1/valid/images
</file>

<file path="download_images.py">
import os
import random
import asyncio
import aiohttp
import aiofiles
from serpapi import GoogleSearch

# Your SerpAPI key
API_KEY = "2d7d083f365a1756060d5117c6774713afe47c52ca844494a86868af3c77a5f7"

# Base directory to save images
SAVE_DIR = "trained_models/images"

# Ensure the base directory exists
if not os.path.exists(SAVE_DIR):
    os.makedirs(SAVE_DIR)

def fetch_image_urls(query, num_images=10):
    """Fetch image URLs from SerpAPI."""
    params = {
        "engine": "google_images",
        "q": query,
        "api_key": API_KEY,
        "num": num_images
    }
    
    search = GoogleSearch(params)
    results = search.get_dict()
    images_results = results.get("images_results", [])
    return [img["original"] for img in images_results[:num_images]]

async def download_image(session, url, category):
    """Download a single image asynchronously using aiohttp and save it asynchronously."""
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/103.0.5060.114 Safari/537.36"
        )
    }
    try:
        async with session.get(url, headers=headers) as response:
            if response.status == 200:
                file_name = f"image_{random.randint(1, 10**24)}.jpg"
                file_path = os.path.join(SAVE_DIR, category, file_name)
                content = await response.read()
                async with aiofiles.open(file_path, "wb") as file:
                    await file.write(content)
                print(f"Downloaded {file_path}")
            else:
                print(f"Failed to download {url} (Status code: {response.status})")
    except Exception as e:
        print(f"Error downloading {url}: {e}")

async def download_images(image_urls, category):
    """Download multiple images concurrently."""
    async with aiohttp.ClientSession() as session:
        tasks = [download_image(session, url, category) for url in image_urls]
        await asyncio.gather(*tasks)

async def main():
    # Define categories with search queries.
    categories = {
        'guns_knives': ['a man with a gun', 'person shooting with a sniper', 'a man holding a knife'],
        'fire_smoke': ['fire burning', 'smoke explosion'],
        'fights': ['people fighting', 'street fight'],
        'realtime_accidents': ['car accident', 'traffic accident'],
        'climber': ['rock climber on a steep cliff', 'mountain climber at summit', 'climber scaling a rocky wall', 'bouldering challenge']
    }

    for category, queries in categories.items():
        # Ensure the category-specific directory exists.
        category_dir = os.path.join(SAVE_DIR, category)
        if not os.path.exists(category_dir):
            os.makedirs(category_dir)
            print(f"Created directory: {category_dir}")
        
        # For each query in the category, fetch and download images concurrently.
        if queries:
            for query in queries:
                print(f"\nFetching images for query '{query}' under category '{category}'...")
                image_urls = fetch_image_urls(query, num_images=100)
                await download_images(image_urls, category)
        else:
            print(f"\nNo specific queries for '{category}'. Using category name as query.")
            image_urls = fetch_image_urls(category, num_images=100)
            await download_images(image_urls, category)

if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="models_results/detect/climbing/args.yaml">
task: detect
mode: train
model: yolov8s.pt
data: /content/datasets/climbing-detection-1/data.yaml
epochs: 40
time: null
patience: 100
batch: 16
imgsz: 640
save: true
save_period: -1
cache: false
device: null
workers: 8
project: null
name: train10
exist_ok: false
pretrained: true
optimizer: auto
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 10
resume: false
amp: true
fraction: 1.0
profile: false
freeze: null
multi_scale: false
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
save_hybrid: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
vid_stride: 1
stream_buffer: false
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
embed: null
show: false
save_frames: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
show_boxes: true
line_width: null
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: false
opset: null
workspace: 4
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
label_smoothing: 0.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
bgr: 0.0
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
auto_augment: randaugment
erasing: 0.4
crop_fraction: 1.0
cfg: null
tracker: botsort.yaml
save_dir: runs/detect/train10
</file>

<file path="models_results/detect/climbing/results.csv">
epoch,         train/box_loss,         train/cls_loss,         train/dfl_loss,   metrics/precision(B),      metrics/recall(B),       metrics/mAP50(B),    metrics/mAP50-95(B),           val/box_loss,           val/cls_loss,           val/dfl_loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 1.7628,                 3.1183,                 2.0384,                0.39845,                0.47826,                0.35994,                0.13771,                  2.248,                 7.5629,                 2.7055,                 0.0006,                 0.0006,                 0.0006
                      2,                 1.7801,                 1.8144,                 1.9976,                0.08099,                0.56522,                0.06135,                 0.0172,                 2.5394,                 25.474,                 3.0906,              0.0011898,              0.0011898,              0.0011898
                      3,                 1.8498,                 1.8854,                 2.0148,                   0.25,                0.17391,                 0.1339,                   0.02,                 3.5047,                 24.094,                 7.7654,              0.0017489,              0.0017489,              0.0017489
                      4,                 1.8533,                 1.9235,                  2.025,                0.01072,                0.04348,                0.00231,                0.00043,                 4.4647,                 4.6366,                 6.6329,              0.0018515,              0.0018515,              0.0018515
                      5,                 1.8619,                 1.8565,                 2.0563,                0.02713,                0.06326,                  0.011,                0.00297,                 3.5428,                 3.2771,                 4.3789,               0.001802,               0.001802,               0.001802
                      6,                 1.8397,                  1.865,                 2.0116,                0.13409,                0.21739,                0.05736,                0.01218,                 2.8558,                 6.7333,                 3.3487,              0.0017525,              0.0017525,              0.0017525
                      7,                 1.7688,                 1.7454,                  1.939,                0.24944,                0.26087,                0.26873,                0.06281,                 2.6401,                 2.4973,                 2.7344,               0.001703,               0.001703,               0.001703
                      8,                 1.7764,                 1.8105,                  1.969,                0.16302,                0.34783,                0.15298,                0.05054,                  2.748,                 2.5474,                 2.8034,              0.0016535,              0.0016535,              0.0016535
                      9,                   1.76,                 1.7009,                 1.9527,                0.24131,                0.30435,                0.21842,                0.05715,                 2.7504,                 2.6176,                 2.9727,               0.001604,               0.001604,               0.001604
                     10,                 1.7185,                 1.6669,                 1.8931,                0.53086,                0.56522,                0.46729,                 0.1587,                 2.2469,                 2.2459,                 2.4469,              0.0015545,              0.0015545,              0.0015545
                     11,                 1.6605,                 1.5768,                  1.871,                0.60453,                0.47826,                0.46917,                0.13553,                 2.3467,                 2.2137,                  2.671,               0.001505,               0.001505,               0.001505
                     12,                 1.7207,                 1.5866,                 1.9058,                0.29439,                0.52174,                0.24806,                 0.0589,                 2.7082,                 2.6601,                 2.9766,              0.0014555,              0.0014555,              0.0014555
                     13,                 1.6579,                 1.6427,                 1.8765,                0.45176,                0.60907,                0.57152,                0.17472,                 2.3063,                 1.9144,                 2.4367,               0.001406,               0.001406,               0.001406
                     14,                 1.5703,                 1.4837,                 1.8001,                 0.4931,                0.43478,                 0.3406,                 0.0661,                 2.5391,                 2.5495,                  2.838,              0.0013565,              0.0013565,              0.0013565
                     15,                 1.6073,                 1.4886,                 1.8075,                0.75397,                0.52174,                0.61685,                0.23963,                 2.2004,                 1.5336,                 2.4481,               0.001307,               0.001307,               0.001307
                     16,                 1.5702,                 1.4679,                 1.7901,                0.53263,                0.82609,                0.69067,                0.27394,                 1.9328,                 1.5108,                 2.1224,              0.0012575,              0.0012575,              0.0012575
                     17,                 1.5542,                   1.39,                 1.7598,                0.63307,                0.69565,                0.71532,                0.27486,                 2.1147,                  1.518,                 2.2358,               0.001208,               0.001208,               0.001208
                     18,                 1.5844,                 1.4172,                 1.7691,                0.62869,                0.44205,                0.54017,                0.14808,                  2.425,                 1.8514,                 2.7353,              0.0011585,              0.0011585,              0.0011585
                     19,                 1.5284,                 1.3767,                 1.7031,                0.79806,                0.68766,                0.77034,                  0.298,                 2.0519,                 1.3743,                 2.1436,               0.001109,               0.001109,               0.001109
                     20,                 1.5007,                 1.3363,                 1.7044,                0.78552,                0.63749,                0.73728,                0.30708,                  2.041,                 1.4441,                 2.1969,              0.0010595,              0.0010595,              0.0010595
                     21,                 1.4769,                  1.285,                 1.7166,                0.70608,                0.82609,                0.79523,                0.31214,                 2.1013,                 1.3778,                 2.2526,                0.00101,                0.00101,                0.00101
                     22,                 1.4598,                  1.253,                 1.6905,                0.69578,                0.69609,                0.73421,                0.37905,                 1.8135,                 1.3058,                 1.8789,              0.0009605,              0.0009605,              0.0009605
                     23,                 1.4122,                  1.182,                 1.6278,                0.77958,                0.65217,                0.79704,                 0.3854,                 1.7133,                 1.2643,                 1.8386,               0.000911,               0.000911,               0.000911
                     24,                  1.423,                 1.2231,                 1.6639,                0.87069,                0.69565,                0.84291,                0.40324,                 1.6739,                 1.1271,                 1.8281,              0.0008615,              0.0008615,              0.0008615
                     25,                 1.4026,                 1.1689,                 1.6432,                0.69755,                0.80262,                0.77475,                0.36298,                 1.7536,                 1.2026,                   1.88,               0.000812,               0.000812,               0.000812
                     26,                 1.3508,                 1.1332,                  1.606,                0.66244,                0.68298,                0.71125,                0.34785,                 1.6398,                  1.219,                 1.8003,              0.0007625,              0.0007625,              0.0007625
                     27,                   1.36,                 1.1207,                 1.5862,                0.71922,                0.55723,                 0.6863,                0.37684,                 1.6904,                 1.3028,                 1.8233,               0.000713,               0.000713,               0.000713
                     28,                  1.338,                 1.0882,                 1.5744,                0.68391,                0.73913,                0.76098,                0.43905,                 1.4878,                  1.149,                 1.6879,              0.0006635,              0.0006635,              0.0006635
                     29,                 1.3122,                 1.0711,                 1.5451,                0.77566,                0.75206,                0.80793,                0.42445,                 1.6745,                 1.2022,                 1.7719,               0.000614,               0.000614,               0.000614
                     30,                 1.3019,                 1.0814,                 1.5478,                0.76914,                0.72472,                0.80464,                0.35868,                 1.7627,                 1.1276,                 1.8617,              0.0005645,              0.0005645,              0.0005645
                     31,                 1.2597,                0.88624,                 1.6206,                0.80719,                 0.6087,                0.76631,                0.40353,                 1.6081,                 1.1578,                 1.7447,               0.000515,               0.000515,               0.000515
                     32,                 1.2203,                0.77432,                 1.6012,                0.61781,                0.84371,                0.75974,                0.43514,                 1.6706,                 1.0313,                 1.7611,              0.0004655,              0.0004655,              0.0004655
                     33,                 1.1911,                0.73637,                 1.5706,                0.83001,                0.65217,                0.76636,                0.41846,                 1.7438,                  1.122,                 1.8852,               0.000416,               0.000416,               0.000416
                     34,                 1.1517,                0.72537,                 1.5343,                0.72764,                0.81343,                0.79679,                0.45488,                 1.5496,                 1.0789,                 1.7061,              0.0003665,              0.0003665,              0.0003665
                     35,                 1.1312,                0.67377,                 1.5151,                0.79834,                0.73913,                0.80659,                 0.4168,                 1.6583,                 1.0866,                 1.7619,               0.000317,               0.000317,               0.000317
                     36,                 1.1244,                0.67268,                 1.5285,                0.67129,                0.86957,                0.83599,                  0.443,                 1.6453,                 1.1103,                 1.7198,              0.0002675,              0.0002675,              0.0002675
                     37,                 1.0809,                0.64872,                 1.4629,                0.83492,                0.66002,                0.81893,                0.43568,                  1.626,                 1.0238,                 1.7982,               0.000218,               0.000218,               0.000218
                     38,                 1.0342,                0.64534,                 1.4468,                0.73636,                0.85047,                0.85593,                0.44288,                  1.693,                0.99618,                 1.8006,              0.0001685,              0.0001685,              0.0001685
                     39,                 1.0411,                 0.6224,                 1.4393,                0.65815,                0.86957,                0.80336,                0.41133,                 1.6895,                 1.0474,                 1.8339,               0.000119,               0.000119,               0.000119
                     40,                 1.0071,                0.60344,                 1.4195,                0.66663,                0.86943,                0.81798,                0.44054,                 1.6578,                 1.0939,                 1.7981,               6.95e-05,               6.95e-05,               6.95e-05
</file>

<file path="models_results/detect/cracks_dents/args.yaml">
task: detect
mode: train
model: yolov8s.pt
data: /content/datasets/Crack-Detection-2/data.yaml
epochs: 10
time: null
patience: 100
batch: 16
imgsz: 640
save: true
save_period: -1
cache: false
device: null
workers: 8
project: null
name: train2
exist_ok: false
pretrained: true
optimizer: auto
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 10
resume: false
amp: true
fraction: 1.0
profile: false
freeze: null
multi_scale: false
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
save_hybrid: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
vid_stride: 1
stream_buffer: false
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
embed: null
show: false
save_frames: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
show_boxes: true
line_width: null
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: false
opset: null
workspace: 4
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
label_smoothing: 0.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
bgr: 0.0
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
auto_augment: randaugment
erasing: 0.4
crop_fraction: 1.0
cfg: null
tracker: botsort.yaml
save_dir: runs/detect/train2
</file>

<file path="models_results/detect/cracks_dents/results.csv">
epoch,         train/box_loss,         train/cls_loss,         train/dfl_loss,   metrics/precision(B),      metrics/recall(B),       metrics/mAP50(B),    metrics/mAP50-95(B),           val/box_loss,           val/cls_loss,           val/dfl_loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 1.4236,                 2.0915,                 1.8744,                0.58478,                0.66614,                0.61024,                0.25742,                 1.8388,                 1.8043,                 2.1276,             0.00066408,             0.00066408,             0.00066408
                      2,                 1.3863,                 1.3515,                 1.8326,                0.60956,                0.47377,                0.55223,                0.27725,                 1.7297,                 1.7254,                  1.861,               0.001199,               0.001199,               0.001199
                      3,                 1.3001,                 1.2245,                 1.7425,                 0.8476,                0.68362,                 0.8246,                0.49494,                 1.3581,                 1.2609,                 1.5858,              0.0016019,              0.0016019,              0.0016019
                      4,                 1.1895,                  1.086,                 1.6603,                0.84946,                0.83148,                0.88883,                0.58067,                  1.158,                0.97244,                 1.3537,               0.001406,               0.001406,               0.001406
                      5,                 1.1153,                0.97271,                 1.5797,                0.86766,                 0.8124,                0.90394,                0.56536,                 1.2364,                0.93234,                 1.4096,               0.001208,               0.001208,               0.001208
                      6,                 1.0627,                0.90067,                 1.5255,                0.82499,                0.87758,                0.91623,                0.62037,                 1.1189,                0.88985,                  1.278,                0.00101,                0.00101,                0.00101
                      7,                0.98714,                0.79611,                 1.4664,                0.93372,                0.85105,                 0.9388,                0.66004,                0.99871,                0.75592,                 1.1949,               0.000812,               0.000812,               0.000812
                      8,                0.93971,                0.72186,                 1.4182,                0.94299,                0.89407,                0.95737,                 0.6955,                 0.9576,                0.67691,                 1.1335,               0.000614,               0.000614,               0.000614
                      9,                0.91191,                0.66427,                 1.3919,                0.93331,                0.91224,                0.96488,                0.71942,                0.94192,                0.62988,                 1.1094,               0.000416,               0.000416,               0.000416
                     10,                0.84322,                 0.6097,                 1.3383,                0.93553,                0.91415,                0.96557,                0.74276,                0.86548,                 0.6139,                 1.0442,               0.000218,               0.000218,               0.000218
</file>

<file path="models_results/detect/fights/args.yaml">
task: detect
mode: train
model: yolov8s.pt
data: /content/datasets/gisc-1/data.yaml
epochs: 100
time: null
patience: 100
batch: 16
imgsz: 640
save: true
save_period: -1
cache: false
device: null
workers: 8
project: null
name: train8
exist_ok: false
pretrained: true
optimizer: auto
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 10
resume: false
amp: true
fraction: 1.0
profile: false
freeze: null
multi_scale: false
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
save_hybrid: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
vid_stride: 1
stream_buffer: false
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
embed: null
show: false
save_frames: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
show_boxes: true
line_width: null
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: false
opset: null
workspace: 4
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
label_smoothing: 0.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
bgr: 0.0
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
auto_augment: randaugment
erasing: 0.4
crop_fraction: 1.0
cfg: null
tracker: botsort.yaml
save_dir: runs/detect/train8
</file>

<file path="models_results/detect/fights/results.csv">
epoch,         train/box_loss,         train/cls_loss,         train/dfl_loss,   metrics/precision(B),      metrics/recall(B),       metrics/mAP50(B),    metrics/mAP50-95(B),           val/box_loss,           val/cls_loss,           val/dfl_loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 1.5826,                 3.2222,                 1.7121,                0.10514,                0.27174,                0.07161,                0.02645,                 2.2676,                 3.2645,                 2.5447,                0.00065,                0.00065,                0.00065
                      2,                 1.8185,                 2.3287,                 1.8637,                0.04981,                0.43478,                0.03682,                0.01192,                 2.6144,                 99.418,                 3.9159,              0.0013036,              0.0013036,              0.0013036
                      3,                 1.9256,                  2.407,                 1.9779,                0.00409,                0.68478,                 0.0037,                0.00124,                    2.9,                    inf,                 8.1449,              0.0019441,              0.0019441,              0.0019441
                      4,                  1.987,                 2.5131,                 2.0397,                0.09072,                0.32609,                0.07352,                0.02245,                 2.6518,                 26.296,                 3.3003,              0.0019406,              0.0019406,              0.0019406
                      5,                 1.9137,                 2.3836,                 1.9698,                0.04727,                 0.1087,                 0.0384,                0.01185,                 2.6912,                 14.808,                 3.1496,              0.0019208,              0.0019208,              0.0019208
                      6,                 1.9411,                  2.376,                 2.0049,                0.00416,                0.26087,                0.00361,                 0.0012,                 3.0041,                 53.615,                 3.5409,               0.001901,               0.001901,               0.001901
                      7,                 1.8407,                 2.3378,                 1.9537,                0.21226,                 0.2314,                0.15463,                 0.0615,                 2.5053,                 2.8027,                 2.7392,              0.0018812,              0.0018812,              0.0018812
                      8,                 1.8215,                 2.2641,                 1.9514,                0.16058,                0.20652,                0.11043,                0.03883,                 2.4926,                 3.7251,                  2.564,              0.0018614,              0.0018614,              0.0018614
                      9,                 1.7674,                 2.1939,                 1.9046,                0.21436,                0.26087,                0.12284,                0.03638,                 2.2915,                 3.7875,                 2.5806,              0.0018416,              0.0018416,              0.0018416
                     10,                 1.7697,                 2.2236,                 1.9015,                0.22621,                0.30435,                0.19673,                0.07254,                 2.0544,                 3.5346,                 2.5133,              0.0018218,              0.0018218,              0.0018218
                     11,                 1.7795,                 2.2125,                 1.8925,                0.30001,                0.31215,                 0.2219,                0.08414,                 2.1136,                 2.5894,                 2.3894,               0.001802,               0.001802,               0.001802
                     12,                 1.7172,                 2.1508,                 1.8342,                0.20905,                0.31522,                0.18817,                0.07655,                 2.0287,                  2.796,                 2.2602,              0.0017822,              0.0017822,              0.0017822
                     13,                 1.7164,                 2.1263,                 1.8358,                0.36538,                0.28791,                0.21949,                 0.0846,                 2.0865,                 2.6769,                 2.2303,              0.0017624,              0.0017624,              0.0017624
                     14,                 1.6926,                 2.0737,                 1.8289,                0.28137,                    0.5,                0.28525,                0.11871,                 1.9141,                 2.4544,                 2.1411,              0.0017426,              0.0017426,              0.0017426
                     15,                 1.6136,                   1.97,                 1.7295,                0.34772,                0.27174,                0.25068,                0.09971,                 1.9887,                 2.5008,                  2.247,              0.0017228,              0.0017228,              0.0017228
                     16,                 1.6638,                 1.9871,                 1.7784,                0.29929,                0.42391,                0.30033,                0.13797,                  1.978,                 2.2751,                 2.2434,               0.001703,               0.001703,               0.001703
                     17,                 1.6199,                 1.9416,                 1.7542,                0.14845,                0.38087,                0.12182,                0.04905,                 1.8322,                 2.5534,                 2.0584,              0.0016832,              0.0016832,              0.0016832
                     18,                 1.5978,                 1.9077,                 1.7313,                0.32602,                0.34783,                0.27733,                0.10719,                 2.1812,                 2.4985,                 2.3631,              0.0016634,              0.0016634,              0.0016634
                     19,                 1.6076,                 1.9168,                 1.7529,                0.26376,                0.36957,                0.25405,                 0.0948,                 1.9434,                 2.7082,                 2.2362,              0.0016436,              0.0016436,              0.0016436
                     20,                  1.555,                 1.8615,                 1.7047,                0.36107,                0.46739,                0.33111,                0.14994,                 1.9349,                 2.1639,                  2.089,              0.0016238,              0.0016238,              0.0016238
                     21,                  1.518,                 1.7551,                 1.6766,                0.37343,                0.35632,                0.28933,                0.13864,                 1.9159,                 2.2948,                 2.0782,               0.001604,               0.001604,               0.001604
                     22,                 1.5727,                 1.8194,                 1.6839,                0.43255,                0.31522,                0.33817,                0.16548,                 1.9123,                 2.1429,                 2.1159,              0.0015842,              0.0015842,              0.0015842
                     23,                 1.5626,                 1.8745,                  1.685,                0.32074,                    0.5,                0.32278,                0.14578,                 1.9608,                 2.2735,                 2.2186,              0.0015644,              0.0015644,              0.0015644
                     24,                 1.4863,                 1.7859,                 1.6542,                0.41782,                0.38043,                0.39416,                0.20092,                 1.7845,                 2.0776,                 2.0003,              0.0015446,              0.0015446,              0.0015446
                     25,                 1.5117,                 1.7247,                 1.6439,                0.40334,                0.44565,                0.39505,                0.20358,                 1.7665,                 2.0847,                 1.9271,              0.0015248,              0.0015248,              0.0015248
                     26,                 1.4859,                 1.6967,                 1.6129,                0.41216,                0.46739,                0.45709,                0.19284,                 1.9608,                 1.9934,                 2.0813,               0.001505,               0.001505,               0.001505
                     27,                 1.5164,                  1.747,                 1.6594,                0.28821,                0.44015,                0.30108,                0.13285,                 1.8526,                 2.2581,                 1.9998,              0.0014852,              0.0014852,              0.0014852
                     28,                 1.4672,                 1.7207,                 1.6162,                0.42193,                0.47826,                0.45296,                0.23048,                  1.724,                 1.9494,                 1.8946,              0.0014654,              0.0014654,              0.0014654
                     29,                 1.4079,                 1.6242,                 1.6113,                 0.4226,                0.45652,                0.44178,                0.22582,                 1.7118,                 2.0929,                 1.9431,              0.0014456,              0.0014456,              0.0014456
                     30,                 1.4848,                 1.6992,                 1.6335,                0.58809,                0.43453,                 0.4648,                0.22514,                 1.8556,                 2.3041,                 2.0653,              0.0014258,              0.0014258,              0.0014258
                     31,                 1.4266,                 1.6598,                 1.6026,                0.49112,                 0.3913,                0.46533,                0.23726,                 1.7878,                 1.9286,                 2.0116,               0.001406,               0.001406,               0.001406
                     32,                 1.4454,                 1.6751,                 1.5982,                0.49101,                0.45652,                0.46711,                0.24884,                 1.6258,                 1.9907,                 1.8444,              0.0013862,              0.0013862,              0.0013862
                     33,                 1.4177,                 1.6483,                 1.5971,                0.49807,                0.44565,                0.46987,                0.25781,                 1.7112,                 1.8745,                 1.8818,              0.0013664,              0.0013664,              0.0013664
                     34,                 1.3941,                 1.5669,                 1.5674,                0.56004,                0.52174,                0.51766,                0.27437,                 1.7388,                 1.9118,                 2.0022,              0.0013466,              0.0013466,              0.0013466
                     35,                 1.3923,                 1.5503,                 1.5712,                0.60273,                0.44565,                0.49165,                  0.274,                 1.6921,                 2.0881,                 1.9678,              0.0013268,              0.0013268,              0.0013268
                     36,                 1.3968,                 1.5689,                 1.5751,                0.49405,                    0.5,                0.43894,                0.23818,                 1.6624,                 1.9581,                 1.9415,               0.001307,               0.001307,               0.001307
                     37,                 1.3317,                  1.553,                  1.547,                0.48048,                0.61957,                0.55525,                0.30912,                 1.6232,                 1.7229,                 1.8516,              0.0012872,              0.0012872,              0.0012872
                     38,                 1.3526,                 1.4969,                 1.5542,                 0.4726,                0.52599,                0.45657,                0.26169,                 1.6157,                 1.8283,                 1.7685,              0.0012674,              0.0012674,              0.0012674
                     39,                 1.3347,                 1.5063,                 1.5371,                0.60784,                0.44565,                0.49938,                0.29072,                 1.6841,                 1.8489,                 1.8858,              0.0012476,              0.0012476,              0.0012476
                     40,                 1.3298,                 1.4639,                  1.499,                0.55001,                0.53144,                0.52836,                0.28072,                 1.7004,                 1.7525,                  1.862,              0.0012278,              0.0012278,              0.0012278
                     41,                 1.3155,                 1.4677,                 1.5062,                0.61754,                0.52174,                0.53342,                0.28773,                 1.6763,                 1.7457,                 1.8861,               0.001208,               0.001208,               0.001208
                     42,                 1.3337,                 1.4581,                 1.5166,                0.64919,                0.46739,                0.56263,                0.31271,                 1.5724,                 1.7391,                 1.8096,              0.0011882,              0.0011882,              0.0011882
                     43,                 1.2946,                 1.4902,                 1.5018,                0.65545,                0.52174,                0.56189,                0.31523,                 1.6346,                  1.814,                 1.8707,              0.0011684,              0.0011684,              0.0011684
                     44,                 1.3096,                 1.4668,                 1.4966,                0.56397,                0.56238,                0.55067,                0.31455,                 1.6011,                 1.6796,                 1.8683,              0.0011486,              0.0011486,              0.0011486
                     45,                 1.3079,                 1.3606,                 1.5001,                0.57828,                0.48913,                0.53188,                0.29708,                 1.6668,                  1.753,                 1.9027,              0.0011288,              0.0011288,              0.0011288
                     46,                 1.2482,                 1.3426,                 1.4586,                0.50656,                0.47826,                0.45699,                0.23921,                 1.8177,                 2.0238,                 2.0395,               0.001109,               0.001109,               0.001109
                     47,                 1.3054,                 1.3702,                 1.4838,                 0.5734,                0.56981,                0.55536,                0.30211,                 1.7145,                 1.7714,                 1.9194,              0.0010892,              0.0010892,              0.0010892
                     48,                 1.2694,                 1.3488,                 1.4579,                0.44365,                0.58696,                0.48721,                0.24651,                  1.734,                 1.7906,                 1.9046,              0.0010694,              0.0010694,              0.0010694
                     49,                 1.2458,                 1.3181,                  1.451,                0.58965,                0.48422,                0.53642,                0.29755,                 1.5663,                 1.6021,                 1.7894,              0.0010496,              0.0010496,              0.0010496
                     50,                 1.2543,                 1.3191,                 1.4547,                0.58281,                0.48913,                0.55579,                0.33217,                 1.4706,                  1.698,                 1.7203,              0.0010298,              0.0010298,              0.0010298
                     51,                 1.2091,                 1.2722,                 1.4155,                0.53149,                0.56522,                0.54208,                0.30886,                 1.5998,                 1.6874,                 1.8091,                0.00101,                0.00101,                0.00101
                     52,                 1.2263,                 1.2713,                 1.4281,                0.56967,                 0.6087,                 0.5713,                0.29275,                 1.7157,                 1.7063,                 1.9353,              0.0009902,              0.0009902,              0.0009902
                     53,                 1.1913,                  1.232,                 1.4079,                0.55549,                    0.5,                0.53265,                0.29355,                 1.5962,                  1.688,                 1.7738,              0.0009704,              0.0009704,              0.0009704
                     54,                  1.217,                 1.2223,                 1.4269,                0.69022,                    0.5,                0.60828,                0.33869,                 1.7542,                 1.6904,                 1.9691,              0.0009506,              0.0009506,              0.0009506
                     55,                 1.1929,                 1.2184,                 1.4171,                0.51643,                0.56522,                 0.5518,                0.31921,                 1.7293,                 1.8147,                  1.938,              0.0009308,              0.0009308,              0.0009308
                     56,                 1.1437,                 1.1907,                 1.3839,                0.61438,                0.57151,                0.61416,                0.34472,                 1.6463,                 1.6804,                 1.8029,               0.000911,               0.000911,               0.000911
                     57,                 1.1945,                 1.2326,                 1.4104,                0.61019,                0.61957,                0.65312,                0.38694,                 1.5643,                 1.6261,                 1.7718,              0.0008912,              0.0008912,              0.0008912
                     58,                 1.1659,                 1.1629,                 1.3987,                0.63027,                0.55589,                0.60426,                0.33401,                 1.7351,                 1.6236,                 1.8889,              0.0008714,              0.0008714,              0.0008714
                     59,                 1.1304,                  1.161,                 1.3493,                0.71196,                0.54348,                0.59955,                0.33125,                 1.6684,                 1.5555,                 1.8335,              0.0008516,              0.0008516,              0.0008516
                     60,                 1.1083,                 1.1323,                 1.3617,                0.53649,                0.51087,                0.56043,                 0.2946,                 1.8194,                 1.8002,                 2.0029,              0.0008318,              0.0008318,              0.0008318
                     61,                 1.1304,                 1.1561,                 1.3781,                0.59689,                 0.6413,                0.61927,                0.34657,                 1.6785,                 1.5651,                 1.8558,               0.000812,               0.000812,               0.000812
                     62,                   1.14,                  1.118,                 1.3827,                0.61132,                0.56522,                0.57514,                0.30896,                 1.7398,                 1.6178,                 1.9235,              0.0007922,              0.0007922,              0.0007922
                     63,                 1.1485,                 1.1254,                 1.3781,                0.58205,                0.55435,                0.55739,                0.31487,                 1.5805,                 1.5909,                 1.7661,              0.0007724,              0.0007724,              0.0007724
                     64,                 1.0793,                 1.0872,                 1.3458,                 0.5906,                0.55435,                0.59045,                0.32638,                 1.6936,                 1.6088,                 1.8811,              0.0007526,              0.0007526,              0.0007526
                     65,                  1.137,                 1.0969,                 1.3815,                0.56902,                0.57609,                0.56407,                0.30122,                 1.6964,                  1.649,                 1.9201,              0.0007328,              0.0007328,              0.0007328
                     66,                 1.0752,                 1.1029,                 1.3472,                0.46945,                0.64442,                0.59632,                 0.3356,                 1.6798,                 1.5712,                 1.8329,               0.000713,               0.000713,               0.000713
                     67,                 1.0427,                 1.0164,                 1.3149,                0.70505,                0.52174,                 0.5777,                0.34391,                 1.6916,                 1.6931,                 1.9108,              0.0006932,              0.0006932,              0.0006932
                     68,                 1.0737,                 1.0355,                 1.3251,                0.55468,                0.58696,                0.56499,                0.32271,                  1.588,                 1.5218,                 1.7786,              0.0006734,              0.0006734,              0.0006734
                     69,                 1.0507,                 1.0029,                 1.3148,                0.56841,                0.66304,                0.63161,                0.32682,                 1.7783,                 1.6191,                 2.0167,              0.0006536,              0.0006536,              0.0006536
                     70,                  1.051,                 1.0211,                 1.3021,                0.55379,                0.58011,                0.52464,                0.28703,                 1.7466,                 1.5969,                 1.9393,              0.0006338,              0.0006338,              0.0006338
                     71,                 1.0533,                0.99568,                 1.3003,                0.58931,                0.68629,                0.67668,                0.36703,                 1.6999,                 1.4879,                 1.9701,               0.000614,               0.000614,               0.000614
                     72,                 1.0499,                0.98082,                 1.3144,                0.62213,                0.55478,                0.61001,                0.34378,                 1.7772,                 1.6036,                 1.9475,              0.0005942,              0.0005942,              0.0005942
                     73,                 1.0186,                0.96026,                 1.2768,                0.56577,                0.63043,                0.59786,                0.34529,                 1.7019,                 1.5494,                 1.8851,              0.0005744,              0.0005744,              0.0005744
                     74,                 1.0008,                0.92614,                 1.2621,                0.65019,                    0.5,                 0.5855,                0.34365,                 1.7112,                 1.5562,                 1.8806,              0.0005546,              0.0005546,              0.0005546
                     75,                 1.0286,                 0.9578,                 1.2823,                0.71002,                 0.5323,                0.62657,                0.37093,                 1.6289,                 1.5875,                 1.8007,              0.0005348,              0.0005348,              0.0005348
                     76,                 1.0095,                0.95881,                 1.2816,                0.65685,                 0.5618,                0.59085,                0.31307,                 1.7223,                 1.5338,                  1.945,               0.000515,               0.000515,               0.000515
                     77,                 1.0075,                0.94098,                   1.28,                 0.6664,                0.56454,                0.64152,                0.34966,                 1.6384,                 1.6022,                 1.8365,              0.0004952,              0.0004952,              0.0004952
                     78,                0.95371,                0.92332,                 1.2539,                0.73548,                0.57609,                0.65494,                0.36567,                 1.6422,                 1.4239,                 1.8641,              0.0004754,              0.0004754,              0.0004754
                     79,                0.97402,                0.90886,                 1.2598,                0.65381,                0.59534,                0.63143,                0.36711,                 1.6594,                 1.4259,                 1.8492,              0.0004556,              0.0004556,              0.0004556
                     80,                0.97208,                0.88291,                 1.2454,                0.68195,                0.58269,                0.62997,                0.35098,                 1.7121,                 1.4069,                 1.8999,              0.0004358,              0.0004358,              0.0004358
                     81,                0.92917,                0.86272,                 1.2449,                0.68135,                0.58696,                0.66028,                0.38243,                 1.6936,                 1.4611,                 1.9031,               0.000416,               0.000416,               0.000416
                     82,                0.92419,                 0.8581,                  1.228,                0.75937,                0.61746,                0.67386,                0.35641,                 1.6825,                 1.5038,                 1.8668,              0.0003962,              0.0003962,              0.0003962
                     83,                0.92701,                0.86057,                 1.2256,                0.64759,                0.61957,                0.67972,                0.37455,                 1.6744,                 1.4577,                 1.8839,              0.0003764,              0.0003764,              0.0003764
                     84,                0.93919,                0.87292,                 1.2472,                0.74057,                0.59783,                0.67506,                0.38698,                 1.6356,                  1.473,                 1.8089,              0.0003566,              0.0003566,              0.0003566
                     85,                0.91104,                0.84141,                 1.2221,                0.77424,                0.57609,                0.66491,                0.37739,                 1.6858,                  1.403,                 1.8887,              0.0003368,              0.0003368,              0.0003368
                     86,                0.91002,                0.84996,                 1.2086,                0.61521,                0.63043,                0.68053,                0.36965,                 1.8462,                 1.5262,                  2.014,               0.000317,               0.000317,               0.000317
                     87,                0.91295,                0.83172,                 1.2121,                 0.7009,                0.59783,                0.65295,                0.36673,                 1.7242,                 1.3482,                 1.9159,              0.0002972,              0.0002972,              0.0002972
                     88,                0.88207,                0.79766,                 1.1926,                0.72425,                0.56522,                 0.6737,                0.38463,                 1.7155,                 1.4124,                 1.9612,              0.0002774,              0.0002774,              0.0002774
                     89,                0.88726,                0.81342,                 1.2096,                0.79196,                0.53795,                0.68215,                0.38365,                 1.7304,                 1.4651,                 1.9446,              0.0002576,              0.0002576,              0.0002576
                     90,                0.88529,                0.82563,                  1.211,                0.72591,                0.57609,                0.66577,                0.39656,                 1.6889,                 1.4434,                   1.88,              0.0002378,              0.0002378,              0.0002378
                     91,                0.76167,                0.68518,                   1.13,                 0.7836,                0.59783,                0.67683,                0.38944,                 1.6999,                  1.411,                 1.8886,               0.000218,               0.000218,               0.000218
                     92,                0.77074,                0.63323,                 1.1328,                0.78122,                0.58696,                 0.6872,                0.38541,                 1.6772,                 1.3939,                 1.8693,              0.0001982,              0.0001982,              0.0001982
                     93,                0.72869,                0.60242,                 1.1232,                 0.7371,                 0.6087,                 0.7248,                 0.3976,                 1.7108,                 1.3283,                 1.9077,              0.0001784,              0.0001784,              0.0001784
                     94,                0.71903,                 0.5787,                 1.1169,                0.69394,                0.65217,                0.70172,                0.40112,                 1.6678,                  1.381,                 1.8755,              0.0001586,              0.0001586,              0.0001586
                     95,                0.71403,                0.57264,                 1.1105,                0.72735,                0.63043,                0.69256,                0.38153,                 1.6706,                 1.3806,                 1.8766,              0.0001388,              0.0001388,              0.0001388
                     96,                0.71646,                0.55702,                  1.103,                0.76329,                0.56084,                0.67075,                0.39565,                 1.7001,                 1.3778,                 1.8987,               0.000119,               0.000119,               0.000119
                     97,                0.70766,                0.53914,                 1.0815,                0.76415,                0.56348,                0.68007,                0.38068,                 1.6976,                 1.3956,                  1.876,               9.92e-05,               9.92e-05,               9.92e-05
                     98,                 0.6952,                0.55077,                 1.0914,                0.76027,                0.58603,                0.68582,                0.37644,                 1.6884,                 1.4126,                 1.8938,               7.94e-05,               7.94e-05,               7.94e-05
                     99,                0.69142,                0.54807,                 1.0949,                0.69577,                0.61957,                0.68393,                0.38152,                 1.6778,                 1.4258,                 1.8798,               5.96e-05,               5.96e-05,               5.96e-05
                    100,                0.67613,                0.52556,                 1.0795,                0.75998,                 0.6087,                 0.6834,                0.38327,                  1.701,                 1.4023,                 1.8902,               3.98e-05,               3.98e-05,               3.98e-05
</file>

<file path="models_results/detect/fire_smoke_new/args.yaml">
task: detect
mode: train
model: yolov8s.pt
data: /content/datasets/firesmoke-3/data.yaml
epochs: 30
time: null
patience: 100
batch: 16
imgsz: 640
save: true
save_period: -1
cache: false
device: null
workers: 8
project: null
name: train3
exist_ok: false
pretrained: true
optimizer: auto
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 10
resume: false
amp: true
fraction: 1.0
profile: false
freeze: null
multi_scale: false
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
save_hybrid: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
vid_stride: 1
stream_buffer: false
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
embed: null
show: false
save_frames: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
show_boxes: true
line_width: null
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: false
opset: null
workspace: 4
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
label_smoothing: 0.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
bgr: 0.0
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
auto_augment: randaugment
erasing: 0.4
crop_fraction: 1.0
cfg: null
tracker: botsort.yaml
save_dir: runs/detect/train3
</file>

<file path="models_results/detect/fire_smoke_new/results.csv">
epoch,         train/box_loss,         train/cls_loss,         train/dfl_loss,   metrics/precision(B),      metrics/recall(B),       metrics/mAP50(B),    metrics/mAP50-95(B),           val/box_loss,           val/cls_loss,           val/dfl_loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 2.0877,                 2.9567,                 2.0568,                 0.2492,                0.21745,                0.15444,                0.04741,                 2.4112,                   3.84,                 2.6328,             0.00054854,             0.00054854,             0.00054854
                      2,                 2.1378,                 2.5287,                 2.1042,                0.11011,                0.11657,                0.03872,                0.01086,                 3.1338,                  12.37,                 3.8262,              0.0010678,              0.0010678,              0.0010678
                      3,                 2.1372,                  2.544,                 2.1095,                0.20299,                0.18021,                 0.1307,                0.04073,                 2.6428,                 3.9794,                 2.8666,              0.0015503,              0.0015503,              0.0015503
                      4,                  2.095,                   2.51,                 2.0823,                0.50421,                 0.1986,                0.20466,                0.07399,                 2.3254,                 2.7836,                 2.4439,               0.001502,               0.001502,               0.001502
                      5,                 2.0654,                 2.4259,                 2.0293,                0.28554,                0.36388,                   0.26,                0.09582,                 2.1123,                 3.0793,                 2.2606,               0.001447,               0.001447,               0.001447
                      6,                 2.0231,                 2.3432,                 2.0076,                0.35147,                0.36029,                0.31776,                 0.1184,                 2.1864,                 2.4929,                 2.2897,              0.0013919,              0.0013919,              0.0013919
                      7,                 2.0045,                 2.3029,                 1.9994,                0.48602,                0.34403,                0.35903,                0.12992,                 2.1585,                 2.2906,                 2.2194,              0.0013369,              0.0013369,              0.0013369
                      8,                 1.9598,                 2.2364,                 1.9608,                0.44839,                0.42434,                0.38523,                0.15246,                 2.0739,                 2.1572,                 2.1766,              0.0012819,              0.0012819,              0.0012819
                      9,                  1.978,                 2.2513,                 1.9621,                 0.3796,                0.38435,                0.31726,                0.11847,                 2.0658,                 2.6528,                 2.1288,              0.0012269,              0.0012269,              0.0012269
                     10,                 1.9442,                 2.1705,                 1.9393,                0.51507,                 0.4372,                0.43062,                0.17699,                 2.0223,                 2.1836,                 2.1112,              0.0011719,              0.0011719,              0.0011719
                     11,                 1.9041,                  2.091,                 1.9063,                0.51304,                 0.4838,                0.47641,                0.19254,                 1.9606,                 2.0503,                 2.0846,              0.0011169,              0.0011169,              0.0011169
                     12,                 1.9206,                 2.0962,                 1.9074,                0.44747,                0.49531,                  0.458,                0.19725,                 2.0489,                 1.9445,                 2.1422,              0.0010619,              0.0010619,              0.0010619
                     13,                  1.865,                 1.9984,                 1.8639,                0.57237,                0.49454,                0.51402,                0.21791,                 1.9407,                 2.0306,                 2.0537,              0.0010069,              0.0010069,              0.0010069
                     14,                 1.8442,                 2.0085,                 1.8765,                0.45021,                0.48065,                0.44516,                0.18606,                 1.9985,                 1.9916,                 2.0986,             0.00095186,             0.00095186,             0.00095186
                     15,                 1.8304,                 1.9314,                 1.8374,                0.59705,                  0.497,                0.53366,                0.22957,                 1.8919,                 1.8704,                 1.9917,             0.00089685,             0.00089685,             0.00089685
                     16,                  1.831,                 1.9149,                 1.8473,                0.59673,                0.47452,                0.51319,                0.21522,                 1.9654,                 1.8694,                 2.0766,             0.00084184,             0.00084184,             0.00084184
                     17,                 1.7971,                 1.9411,                 1.8364,                0.57932,                 0.5237,                0.53374,                0.22823,                 1.9249,                 1.8521,                 2.0307,             0.00078682,             0.00078682,             0.00078682
                     18,                 1.8018,                 1.8349,                 1.8003,                 0.6851,                0.52224,                0.58127,                0.25516,                 1.9427,                 1.6769,                 2.0105,             0.00073181,             0.00073181,             0.00073181
                     19,                 1.7797,                 1.8169,                 1.8183,                0.62009,                0.55049,                 0.5629,                0.24794,                 1.8843,                 1.7924,                 1.9986,              0.0006768,              0.0006768,              0.0006768
                     20,                 1.7388,                 1.7561,                 1.7661,                0.69156,                0.55366,                0.60328,                0.26672,                 1.9352,                 1.7238,                 2.0221,             0.00062179,             0.00062179,             0.00062179
                     21,                 1.8107,                 1.7568,                  1.873,                  0.659,                0.55902,                0.60732,                0.27178,                 1.8689,                 1.6341,                 1.9851,             0.00056678,             0.00056678,             0.00056678
                     22,                 1.7975,                 1.6834,                   1.85,                0.63402,                0.58733,                0.60247,                0.27355,                 1.8693,                 1.6114,                 1.9693,             0.00051177,             0.00051177,             0.00051177
                     23,                 1.7415,                 1.6011,                 1.8196,                 0.6698,                 0.5958,                0.63003,                0.29118,                 1.8647,                 1.5893,                  1.979,             0.00045676,             0.00045676,             0.00045676
                     24,                 1.7207,                 1.5799,                 1.8196,                 0.6955,                0.60852,                0.63758,                0.29551,                 1.8236,                 1.5558,                 1.9518,             0.00040175,             0.00040175,             0.00040175
                     25,                 1.6855,                 1.5158,                 1.7868,                0.73559,                0.58648,                0.63466,                0.28673,                 1.8699,                 1.5472,                 1.9659,             0.00034674,             0.00034674,             0.00034674
                     26,                 1.6794,                 1.4681,                 1.7653,                0.69862,                0.60833,                0.64645,                0.30501,                 1.8217,                 1.4753,                 1.9328,             0.00029172,             0.00029172,             0.00029172
                     27,                 1.6485,                  1.437,                 1.7499,                0.72093,                0.61335,                0.65997,                0.30316,                 1.8617,                 1.4695,                 1.9638,             0.00023671,             0.00023671,             0.00023671
                     28,                 1.5954,                 1.3695,                 1.7026,                0.71185,                0.60606,                0.66265,                0.31629,                 1.8177,                 1.4499,                  1.919,              0.0001817,              0.0001817,              0.0001817
                     29,                 1.6014,                 1.3599,                 1.7152,                0.74556,                 0.6205,                 0.6799,                0.31471,                 1.8313,                 1.4258,                 1.9329,             0.00012669,             0.00012669,             0.00012669
                     30,                 1.5929,                 1.3121,                 1.6974,                 0.7885,                0.62289,                0.69041,                0.32783,                 1.8357,                  1.402,                 1.9284,             7.1681e-05,             7.1681e-05,             7.1681e-05
</file>

<file path="models_results/detect/fire_smoke_prev(not_used)/args.yaml">
task: detect
mode: train
model: yolov8s.pt
data: /content/datasets/Fire-Smoke-Detection-1/data.yaml
epochs: 4
time: null
patience: 100
batch: 16
imgsz: 640
save: true
save_period: -1
cache: false
device: null
workers: 8
project: null
name: train4
exist_ok: false
pretrained: true
optimizer: auto
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 10
resume: false
amp: true
fraction: 1.0
profile: false
freeze: null
multi_scale: false
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
save_hybrid: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
vid_stride: 1
stream_buffer: false
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
embed: null
show: false
save_frames: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
show_boxes: true
line_width: null
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: false
opset: null
workspace: 4
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
label_smoothing: 0.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
bgr: 0.0
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
auto_augment: randaugment
erasing: 0.4
crop_fraction: 1.0
cfg: null
tracker: botsort.yaml
save_dir: runs/detect/train4
</file>

<file path="models_results/detect/fire_smoke_prev(not_used)/results.csv">
epoch,         train/box_loss,         train/cls_loss,         train/dfl_loss,   metrics/precision(B),      metrics/recall(B),       metrics/mAP50(B),    metrics/mAP50-95(B),           val/box_loss,           val/cls_loss,           val/dfl_loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 0.5058,                0.88774,                0.94869,                0.90842,                0.86317,                0.93623,                0.80461,                0.47322,                0.57844,                0.90487,             0.00047503,             0.00047503,             0.00047503
                      2,                0.38593,                0.45914,                0.88765,                0.94762,                0.94162,                0.97834,                 0.8876,                0.36591,                0.39021,                0.84562,              0.0007159,              0.0007159,              0.0007159
                      3,                0.34074,                0.38084,                0.87061,                0.97352,                 0.9665,                0.98722,                0.92313,                0.30016,                0.29319,                 0.8076,             0.00072099,             0.00072099,             0.00072099
                      4,                0.28828,                0.30748,                 0.8554,                0.97586,                0.96862,                0.98677,                0.93808,                0.25184,                0.24398,                0.79672,             0.00036797,             0.00036797,             0.00036797
</file>

<file path="models_results/detect/guns_knives/args.yaml">
task: detect
mode: train
model: yolov8s.pt
data: /content/datasets/guns_n_knives-3/data.yaml
epochs: 10
time: null
patience: 100
batch: 16
imgsz: 640
save: true
save_period: -1
cache: false
device: null
workers: 8
project: null
name: train
exist_ok: false
pretrained: true
optimizer: auto
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 10
resume: false
amp: true
fraction: 1.0
profile: false
freeze: null
multi_scale: false
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
save_hybrid: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
vid_stride: 1
stream_buffer: false
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
embed: null
show: false
save_frames: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
show_boxes: true
line_width: null
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: false
opset: null
workspace: 4
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
label_smoothing: 0.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
bgr: 0.0
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
auto_augment: randaugment
erasing: 0.4
crop_fraction: 1.0
cfg: null
tracker: botsort.yaml
save_dir: runs/detect/train
</file>

<file path="models_results/detect/guns_knives/results.csv">
epoch,         train/box_loss,         train/cls_loss,         train/dfl_loss,   metrics/precision(B),      metrics/recall(B),       metrics/mAP50(B),    metrics/mAP50-95(B),           val/box_loss,           val/cls_loss,           val/dfl_loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 2.0019,                 2.8285,                 1.9314,                0.29839,                0.24774,                0.19637,                0.07923,                 2.2764,                 2.8712,                 2.2836,             0.00055438,             0.00055438,             0.00055438
                      2,                 2.1285,                 2.5271,                 2.0771,                0.38347,                0.31236,                0.27987,                0.12021,                 2.0737,                 2.5585,                  2.092,              0.0010001,              0.0010001,              0.0010001
                      3,                 2.0556,                 2.3561,                 2.0373,                0.38113,                0.31715,                 0.2645,                 0.1174,                 2.0768,                 2.3173,                 2.0758,              0.0013359,              0.0013359,              0.0013359
                      4,                 1.9322,                 2.1249,                 1.9231,                0.51729,                0.40126,                0.40201,                0.18914,                  1.892,                 2.0399,                 1.9248,              0.0011719,              0.0011719,              0.0011719
                      5,                 1.8335,                 1.9061,                 1.8331,                0.59898,                 0.4848,                 0.5146,                0.25275,                 1.7816,                 1.6847,                 1.8269,              0.0010069,              0.0010069,              0.0010069
                      6,                 1.7505,                 1.7426,                 1.7583,                0.69132,                0.57401,                0.61258,                0.32432,                 1.6707,                 1.4562,                 1.7486,             0.00084184,             0.00084184,             0.00084184
                      7,                 1.6731,                 1.5746,                 1.6955,                0.74675,                0.60196,                 0.6522,                0.34961,                 1.6443,                 1.3729,                 1.6794,              0.0006768,              0.0006768,              0.0006768
                      8,                 1.6049,                 1.4454,                 1.6384,                0.76556,                0.61585,                0.66173,                0.37113,                 1.5812,                 1.2744,                 1.6308,             0.00051177,             0.00051177,             0.00051177
                      9,                 1.5383,                 1.3247,                 1.5815,                0.81434,                 0.6558,                0.71399,                0.40444,                 1.5527,                 1.1778,                 1.6029,             0.00034674,             0.00034674,             0.00034674
                     10,                 1.4801,                 1.2213,                 1.5316,                0.82059,                0.68873,                0.73336,                0.42624,                 1.5162,                 1.0976,                 1.5762,              0.0001817,              0.0001817,              0.0001817
</file>

<file path="models_results/detect/realtime_accident/args.yaml">
task: detect
mode: train
model: yolov8s.pt
data: /content/datasets/Real-Time-Accident-Detection-1/data.yaml
epochs: 10
time: null
patience: 100
batch: 16
imgsz: 640
save: true
save_period: -1
cache: false
device: null
workers: 8
project: null
name: train3
exist_ok: false
pretrained: true
optimizer: auto
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 10
resume: false
amp: true
fraction: 1.0
profile: false
freeze: null
multi_scale: false
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
save_hybrid: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
vid_stride: 1
stream_buffer: false
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
embed: null
show: false
save_frames: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
show_boxes: true
line_width: null
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: false
opset: null
workspace: 4
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
label_smoothing: 0.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
bgr: 0.0
mosaic: 1.0
mixup: 0.0
copy_paste: 0.0
auto_augment: randaugment
erasing: 0.4
crop_fraction: 1.0
cfg: null
tracker: botsort.yaml
save_dir: runs/detect/train3
</file>

<file path="models_results/detect/realtime_accident/results.csv">
epoch,         train/box_loss,         train/cls_loss,         train/dfl_loss,   metrics/precision(B),      metrics/recall(B),       metrics/mAP50(B),    metrics/mAP50-95(B),           val/box_loss,           val/cls_loss,           val/dfl_loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 1.0629,                 1.6355,                 1.1058,                0.59874,                0.31555,                0.34808,                0.17466,                 1.7981,                 1.5871,                 1.5245,             0.00023747,             0.00023747,             0.00023747
                      2,                0.92766,                0.86574,                 1.0407,                 0.5258,                0.32984,                0.34126,                0.17075,                 1.7772,                 1.5167,                   1.51,              0.0004284,              0.0004284,              0.0004284
                      3,                0.89635,                0.80098,                 1.0321,                0.65227,                0.34447,                0.37122,                0.19447,                 1.7683,                 1.4283,                 1.4988,              0.0005722,              0.0005722,              0.0005722
                      4,                0.85152,                0.71392,                  1.007,                0.67732,                0.42016,                0.44583,                 0.2232,                 1.7478,                 1.3792,                   1.46,             0.00050194,             0.00050194,             0.00050194
                      5,                0.80848,                0.63422,                0.98869,                0.59819,                0.48783,                0.45952,                 0.2521,                  1.714,                 1.3735,                 1.4423,             0.00043126,             0.00043126,             0.00043126
                      6,                0.76869,                0.57317,                0.96844,                 0.5663,                0.50767,                0.47601,                0.24983,                 1.7037,                 1.4533,                 1.4348,             0.00036057,             0.00036057,             0.00036057
                      7,                0.72921,                0.52233,                0.95459,                0.63744,                0.54195,                0.53901,                0.29599,                  1.714,                 1.2973,                  1.465,             0.00028988,             0.00028988,             0.00028988
                      8,                0.69686,                0.47267,                0.93875,                0.63425,                0.55268,                0.56071,                0.32345,                 1.6666,                 1.4061,                 1.4248,              0.0002192,              0.0002192,              0.0002192
                      9,                0.67157,                0.43585,                0.92766,                0.77175,                 0.5244,                0.60119,                0.34503,                 1.6314,                 1.3353,                 1.3946,             0.00014851,             0.00014851,             0.00014851
                     10,                0.64551,                0.40509,                0.91818,                0.73697,                0.55385,                0.59447,                0.33724,                 1.6406,                 1.3776,                 1.4026,             7.7826e-05,             7.7826e-05,             7.7826e-05
</file>

<file path="predictions.py">
# import os
# from ultralytics import YOLO
# import cv2
# import torch

# import time 

# def process_images():
#     # Create results directory if it doesn't exist
#     print("CUDA Version:", torch.version)
#     print("GPU Available:", torch.cuda.device_count() > 0)
#     results_dir = os.path.join('trained_models', 'results')
#     os.makedirs(results_dir, exist_ok=True)

#     # Dictionary mapping image folders to their corresponding model files
#     model_mapping = {
#         # 'climber': 'climber.pt',
#         # 'fights': 'fights.pt',
#         # 'fire_smoke': 'fire_smoke.pt',
#         # 'guns_knives': 'guns_knives.pt',
#         'realtime_accidents': 'realtime_accident.pt'
#     }

#     # Process each category
#     for category, model_file in model_mapping.items():
#         print(f"Processing {category} images...")

#         # Create category-specific results directory
#         category_results_dir = os.path.join(results_dir, category)
#         os.makedirs(category_results_dir, exist_ok=True)

#         # Load the corresponding model
#         model_path = os.path.join('trained_models', 'model_weights', model_file)
#         if not os.path.exists(model_path):
#             print(f"Warning: Model file {model_file} not found!")
#             print(model_path)
#             continue

#         model = YOLO(model_path).to('cuda')

#         # Process all images in the category folder
#         image_dir = os.path.join('trained_models', 'images', category)
#         if not os.path.exists(image_dir):
#             print(f"Warning: Image directory {category} not found!")
#             print(image_dir)
#             continue

#         # Supported image extensions
#         image_extensions = ('.jpg', '.jpeg', '.png', '.bmp')

#         # Process each image in the category folder
#         for image_file in os.listdir(image_dir):
#             if os.path.splitext(image_file.lower())[1] in image_extensions:
#                 image_path = os.path.join(image_dir, image_file)
#                 try:
#                     # Run prediction
#                     results = model(image_path)

#                     # Get the result image with boxes drawn
#                     result_image = results[0].plot()

#                     # Save the result
#                     output_path = os.path.join(category_results_dir, image_file)
#                     cv2.imwrite(output_path, result_image)

#                     print(f"Processed: {image_file}")

#                 except Exception as e:
#                     print(f"Error processing {image_file}: {str(e)}")

# if __name__ == "__main__":
#     ti=time.time()
#     process_images()

#     print("Processing complete!")
#     print(f"Time Taken: {(time.time()-ti)}")  


    #batch inference



import os
from ultralytics import YOLO
import cv2
import torch
from pathlib import Path
import numpy as np
from typing import List, Tuple
import time

def load_images(image_paths: List[str], batch_size: int = 10) -> List[List[str]]:
    """Split image paths into batches."""
    return [image_paths[i:i + batch_size] for i in range(0, len(image_paths), batch_size)]

def process_images(batch_size: int = 10):
    print("CUDA Version:", torch.__version__)
    print("GPU Available:", torch.cuda.device_count() > 0)
    
    # Create results directory
    results_dir = Path('trained_models/results')
    results_dir.mkdir(parents=True, exist_ok=True)
    
    # Model mapping
    model_mapping = {
        # 'realtime_accidents': 'realtime_accident.pt',
        # Uncomment to add more categories
        # 'climber': 'climber.pt',
        # 'fights': 'fights.pt',
        'fire_smoke': 'fire_smoke.pt',
        # 'guns_knives': 'guns_knives.pt',
    }
    
    # Supported image extensions
    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp')
    
    # Process each category
    for category, model_file in model_mapping.items():
        print(f"\nProcessing {category} images...")
        
        # Setup paths
        category_results_dir = results_dir / category
        category_results_dir.mkdir(exist_ok=True)
        
        model_path = Path('trained_models/model_weights') / model_file
        if not model_path.exists():
            print(f"Warning: Model file {model_file} not found at {model_path}")
            continue
            
        # Load model
        model = YOLO(str(model_path)).to('cuda')
        
        # Get image paths
        image_dir = Path('trained_models/images') / category
        if not image_dir.exists():
            print(f"Warning: Image directory not found at {image_dir}")
            continue
            
        # Collect all valid image paths
        image_paths = [
            str(f) for f in image_dir.iterdir()
            if f.suffix.lower() in image_extensions
        ]
        
        if not image_paths:
            print(f"No valid images found in {image_dir}")
            continue
            
        # Process images in batches
        batches = load_images(image_paths, batch_size)
        total_batches = len(batches)
        
        for batch_idx, batch in enumerate(batches, 1):
            try:
                # Run batch prediction
                results = model(batch, stream=True)  # stream=True for better memory efficiency
                
                # Process each result in the batch
                for img_path, result in zip(batch, results):
                    result_image = result.plot()
                    output_path = category_results_dir / Path(img_path).name
                    cv2.imwrite(str(output_path), result_image)
                
                print(f"Processed batch {batch_idx}/{total_batches} "
                      f"({len(batch)} images)")
                
            except Exception as e:
                print(f"Error processing batch {batch_idx}: {str(e)}")
                continue

if __name__ == "__main__":
    start_time = time.time()
    process_images(batch_size=16)  # Adjust batch size as needed
    
    duration = time.time() - start_time
    print("\nProcessing complete!")
    print(f"Total time taken: {duration:.2f} seconds")
</file>

<file path="requirements.txt">
fastapi==0.108.0
uvicorn[standard]
ultralytics
numpy
keras
opencv-python
requests
boto3
dnspython
python-decouple
face-recognition
python-multipart
roboflow
inference-sdk
tensorflow


# tensorflow[and-cuda]
</file>

<file path="temp.py">
from ultralytics import YOLO
import requests
from PIL import Image
from io import BytesIO
#generates random number
from random import randint
def predict(image_url,type):
    # Load the trained model
    
    model = YOLO(f'./trained_models/model_weights/{type}.pt').to('cuda')
    #for local image
    # img = Image.open('./images/gun.png')
    # Fetch the image from the URL
    response = requests.get(image_url)
    img=Image.open(BytesIO(response.content))
    
    # Perform prediction
    results = model(img)
    
    # Display or return results
    for result in results:
        boxes = result.boxes
        masks = result.masks  
        keypoints = result.keypoints
        probs = result.probs 
        obb = result.obb 
        # result.show() 
        result.save(filename=f"./trained_models/result_{type}_{randint(1,100)}.jpg")

# Example usage
image_url = 'https://media.istockphoto.com/id/108224113/photo/agent-007.jpg?s=612x612&w=0&k=20&c=zD78DoadOUbfZgPpyXUXiLscsAVTsBujidCoo4btvDM='
predict_accident(image_url,'guns_knives')
# import torch
# print(f"CUDA available: {torch.cuda.is_available()}")
# print(f"Current device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")
# import torch
# print("CUDA Version:", torch.__version__)
# print("GPU Available:", torch.cuda.device_count() > 0)
</file>

<file path="training_code/models_training_code_new.ipynb">
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 83039,
     "status": "ok",
     "timestamp": 1717393178669,
     "user": {
      "displayName": "afith 234",
      "userId": "04481233657332223077"
     },
     "user_tz": -330
    },
    "id": "xSOpctm7twwa",
    "outputId": "d9093eeb-ad79-489c-a2ad-2030a242edd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h/content\n",
      "/content/datasets\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet ultralytics\n",
    "!pip install --quiet roboflow\n",
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)\n",
    "!mkdir {HOME}/datasets\n",
    "%cd {HOME}/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 456,
     "status": "error",
     "timestamp": 1717335506247,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "16670161079480334602"
     },
     "user_tz": -330
    },
    "id": "TEJIuaJJchlF",
    "outputId": "cc1c3fc7-a75d-4ef8-ec86-4160b7899e91"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-fa198b04c639>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-fa198b04c639>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    accident detection model\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#accident detection model\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"0cCp3vcWRdYFCnoJzWu7\")\n",
    "project = rf.workspace(\"abc-llt0y\").project(\"accidetect-a9uvo\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1647002,
     "status": "ok",
     "timestamp": 1717331978544,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "16670161079480334602"
     },
     "user_tz": -330
    },
    "id": "h5GUkZRbOxHu",
    "outputId": "7fdd620a-4223-4ecc-fe3e-b8ee8c463074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n",
      "100% 21.5M/21.5M [00:00<00:00, 188MB/s]\n",
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/AcciDetect-3/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100% 755k/755k [00:00<00:00, 26.9MB/s]\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11139470 parameters, 11139454 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100% 6.23M/6.23M [00:00<00:00, 121MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/AcciDetect-3/train/labels... 5849 images, 0 backgrounds, 0 corrupt: 100% 5849/5849 [00:02<00:00, 1973.91it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/AcciDetect-3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/AcciDetect-3/valid/labels... 712 images, 0 backgrounds, 0 corrupt: 100% 712/712 [00:00<00:00, 1260.40it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/AcciDetect-3/valid/labels.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 512 train, 512 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10       2.7G      1.118      1.585      1.095         55        512: 100% 366/366 [02:34<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  96% 22/23 [00:11<00:00,  1.51it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:12<00:00,  1.83it/s]\n",
      "                   all        712       3335      0.797      0.438      0.555      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      2.65G     0.9806     0.9133      1.026         35        512: 100% 366/366 [02:25<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:09<00:00,  2.39it/s]\n",
      "                   all        712       3335      0.603       0.52      0.528      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      2.61G     0.9547     0.8525      1.019         33        512: 100% 366/366 [02:23<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:09<00:00,  2.49it/s]\n",
      "                   all        712       3335      0.675      0.563      0.599      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      2.64G     0.9104      0.752          1         40        512: 100% 366/366 [02:25<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:09<00:00,  2.36it/s]\n",
      "                   all        712       3335      0.764      0.604      0.658      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      2.64G     0.8586     0.6735     0.9796         58        512: 100% 366/366 [02:23<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:12<00:00,  1.82it/s]\n",
      "                   all        712       3335      0.741      0.727      0.764      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      2.63G      0.826     0.6167     0.9657         35        512: 100% 366/366 [02:22<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:13<00:00,  1.75it/s]\n",
      "                   all        712       3335      0.835      0.717       0.79      0.637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      2.64G     0.7862     0.5595     0.9482         38        512: 100% 366/366 [02:22<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:13<00:00,  1.72it/s]\n",
      "                   all        712       3335      0.747      0.812      0.863      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      2.65G     0.7555     0.5046     0.9347         29        512: 100% 366/366 [02:23<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:13<00:00,  1.77it/s]\n",
      "                   all        712       3335      0.759      0.885      0.912      0.761\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      2.63G     0.7297     0.4717     0.9256         41        512: 100% 366/366 [02:22<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:13<00:00,  1.70it/s]\n",
      "                   all        712       3335      0.908      0.796      0.912      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      2.64G     0.6996     0.4391     0.9153         54        512: 100% 366/366 [02:22<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:11<00:00,  2.01it/s]\n",
      "                   all        712       3335      0.794      0.864      0.925      0.796\n",
      "\n",
      "10 epochs completed in 0.441 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11129454 parameters, 0 gradients, 28.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:14<00:00,  1.58it/s]\n",
      "                   all        712       3335      0.793      0.864      0.925      0.795\n",
      "                  bike        177        448        0.9      0.944      0.967      0.801\n",
      "    bike_bike_accident         34         34      0.818      0.853      0.949      0.794\n",
      "  bike_person_accident         15         15      0.777          1      0.995      0.884\n",
      "                   car        546       1996      0.925      0.973      0.982      0.833\n",
      "     car_bike_accident         31         31      0.641      0.903      0.942      0.837\n",
      "      car_car_accident        313        322      0.923      0.978      0.987      0.905\n",
      "   car_object_accident         33         33      0.788      0.939       0.93      0.844\n",
      "   car_person_accident          5          5      0.529      0.234      0.614      0.567\n",
      "                person        185        451      0.834      0.949      0.961      0.691\n",
      "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=10 imgsz=512 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 14433,
     "status": "ok",
     "timestamp": 1717341201205,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "clpBvaUat63X",
    "outputId": "59bbf352-8460-472a-a740-63537eb3d027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Real-Time-Accident-Detection-1 to yolov8:: 100%|| 270015/270015 [00:09<00:00, 28409.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Real-Time-Accident-Detection-1 in yolov8:: 100%|| 14767/14767 [00:02<00:00, 6149.34it/s]\n"
     ]
    }
   ],
   "source": [
    "#model that has api present\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"puyush-fipgg\").project(\"real-time-accident-detection\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 462569,
     "status": "ok",
     "timestamp": 1717343159029,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "BtLtEv5XyOCK",
    "outputId": "c92dbe31-6175-4008-b045-9e1e9afc7366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/Real-Time-Accident-Detection-1/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11139470 parameters, 11139454 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/Real-Time-Accident-Detection-1/train/labels.cache... 7125 images, 0 backgrounds, 0 corrupt: 100% 7125/7125 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Real-Time-Accident-Detection-1/valid/labels.cache... 254 images, 0 backgrounds, 0 corrupt: 100% 254/254 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.23G      1.063      1.635      1.106         23        640: 100% 446/446 [02:51<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:03<00:00,  2.62it/s]\n",
      "                   all        254       1807      0.599      0.316      0.348      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10       4.2G     0.9277     0.8657      1.041         26        640: 100% 446/446 [02:43<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:04<00:00,  1.91it/s]\n",
      "                   all        254       1807      0.526       0.33      0.341      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      4.21G     0.8963      0.801      1.032          9        640: 100% 446/446 [02:43<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:05<00:00,  1.49it/s]\n",
      "                   all        254       1807      0.652      0.344      0.371      0.194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      4.19G     0.8515     0.7139      1.007         21        640: 100% 446/446 [02:43<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:05<00:00,  1.57it/s]\n",
      "                   all        254       1807      0.677       0.42      0.446      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      4.18G     0.8085     0.6342     0.9887         13        640: 100% 446/446 [02:43<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:03<00:00,  2.31it/s]\n",
      "                   all        254       1807      0.598      0.488       0.46      0.252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      4.19G     0.7687     0.5732     0.9684         10        640: 100% 446/446 [02:45<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:02<00:00,  2.72it/s]\n",
      "                   all        254       1807      0.566      0.508      0.476       0.25\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      4.17G     0.7292     0.5223     0.9546         12        640: 100% 446/446 [02:45<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:02<00:00,  2.72it/s]\n",
      "                   all        254       1807      0.637      0.542      0.539      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10       4.2G     0.6969     0.4727     0.9387         13        640: 100% 446/446 [02:43<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:02<00:00,  2.69it/s]\n",
      "                   all        254       1807      0.634      0.553      0.561      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      4.19G     0.6716     0.4359     0.9277         14        640: 100% 446/446 [02:44<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:04<00:00,  1.88it/s]\n",
      "                   all        254       1807      0.772      0.524      0.601      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      4.23G     0.6455     0.4051     0.9182         15        640: 100% 446/446 [02:40<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:05<00:00,  1.47it/s]\n",
      "                   all        254       1807      0.737      0.554      0.594      0.337\n",
      "\n",
      "10 epochs completed in 0.473 hours.\n",
      "Optimizer stripped from runs/detect/train3/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train3/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train3/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11129454 parameters, 0 gradients, 28.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:12<00:00,  1.57s/it]\n",
      "                   all        254       1807      0.771      0.524      0.601      0.345\n",
      "                  bike        106        374       0.91      0.624      0.809      0.376\n",
      "    bike_bike_accident         14         14      0.625      0.643      0.549      0.342\n",
      "  bike_object_accident          2          2          1          0     0.0108    0.00325\n",
      "  bike_person_accident          9          9      0.451      0.667       0.62      0.285\n",
      "                   car        205        836      0.909      0.616      0.789      0.474\n",
      "     car_bike_accident         28         28      0.781      0.536      0.664      0.418\n",
      "      car_car_accident         94         94      0.776      0.883      0.793      0.564\n",
      "   car_object_accident         12         12      0.467       0.25      0.362      0.237\n",
      "   car_person_accident          4          4      0.913       0.75       0.87      0.524\n",
      "                person        111        434      0.882      0.275      0.546      0.226\n",
      "Speed: 0.6ms preprocess, 5.9ms inference, 0.0ms loss, 6.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19184,
     "status": "ok",
     "timestamp": 1717394572602,
     "user": {
      "displayName": "afith 234",
      "userId": "04481233657332223077"
     },
     "user_tz": -330
    },
    "id": "7DZsBRdlysoJ",
    "outputId": "21b0c472-b387-47d4-ca94-c66544e6b01b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWpDcEok95t0"
   },
   "outputs": [],
   "source": [
    "##weapons dection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 16160,
     "status": "ok",
     "timestamp": 1717336226287,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "HFH0l64pKvDY",
    "outputId": "0a4dc41d-5965-4c2f-9f13-5374e7dc1d7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in guns_n_knives-3 to yolov8:: 100%|| 275489/275489 [00:04<00:00, 63920.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to guns_n_knives-3 in yolov8:: 100%|| 19682/19682 [00:05<00:00, 3678.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"crime-detection\").project(\"guns_n_knives-h4bky\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1899798,
     "status": "ok",
     "timestamp": 1717338175319,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "aepKMttyK64e",
    "outputId": "20f50daf-f234-4230-ee61-88200f791294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n",
      "100% 21.5M/21.5M [00:00<00:00, 181MB/s]\n",
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/guns_n_knives-3/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100% 755k/755k [00:00<00:00, 22.4MB/s]\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11136374 parameters, 11136358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100% 6.23M/6.23M [00:00<00:00, 117MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/guns_n_knives-3/train/labels... 6885 images, 0 backgrounds, 0 corrupt: 100% 6885/6885 [00:03<00:00, 1853.43it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/guns_n_knives-3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/guns_n_knives-3/valid/labels... 1969 images, 0 backgrounds, 0 corrupt: 100% 1969/1969 [00:01<00:00, 1083.15it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/guns_n_knives-3/valid/labels.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.25G      2.002      2.828      1.931         13        640: 100% 431/431 [02:43<00:00,  2.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:25<00:00,  2.39it/s]\n",
      "                   all       1969       2818      0.298      0.248      0.196     0.0792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      4.22G      2.129      2.527      2.077          6        640: 100% 431/431 [02:35<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:25<00:00,  2.43it/s]\n",
      "                   all       1969       2818      0.383      0.312       0.28       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      4.15G      2.056      2.356      2.037          8        640: 100% 431/431 [02:33<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:23<00:00,  2.60it/s]\n",
      "                   all       1969       2818      0.381      0.317      0.265      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      4.18G      1.932      2.125      1.923          6        640: 100% 431/431 [02:34<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:24<00:00,  2.50it/s]\n",
      "                   all       1969       2818      0.517      0.401      0.402      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      4.15G      1.834      1.906      1.833          8        640: 100% 431/431 [02:39<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:24<00:00,  2.49it/s]\n",
      "                   all       1969       2818      0.599      0.485      0.515      0.253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      4.18G      1.751      1.743      1.758          5        640: 100% 431/431 [02:38<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:26<00:00,  2.31it/s]\n",
      "                   all       1969       2818      0.691      0.574      0.613      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10       4.3G      1.673      1.575      1.696          5        640: 100% 431/431 [02:38<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:24<00:00,  2.52it/s]\n",
      "                   all       1969       2818      0.747      0.602      0.652       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      4.17G      1.605      1.445      1.638          8        640: 100% 431/431 [02:35<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:24<00:00,  2.49it/s]\n",
      "                   all       1969       2818      0.766      0.616      0.662      0.371\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      4.15G      1.538      1.325      1.581          6        640: 100% 431/431 [02:32<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:25<00:00,  2.44it/s]\n",
      "                   all       1969       2818      0.814      0.656      0.714      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      4.19G       1.48      1.221      1.532         10        640: 100% 431/431 [02:32<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:22<00:00,  2.71it/s]\n",
      "                   all       1969       2818      0.821      0.689      0.733      0.426\n",
      "\n",
      "10 epochs completed in 0.510 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:30<00:00,  2.03it/s]\n",
      "                   all       1969       2818       0.82      0.689      0.733      0.426\n",
      "                   gun        970       1559      0.766      0.526      0.562      0.316\n",
      "                 knife        999       1259      0.874      0.852      0.905      0.536\n",
      "Speed: 0.3ms preprocess, 4.7ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10073,
     "status": "ok",
     "timestamp": 1717339700014,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "yykMrdz4LjrV",
    "outputId": "b1e653c5-ce00-41e3-a0f2-5cccfc9151ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Crack-Detection-2 to yolov8:: 100%|| 213409/213409 [00:05<00:00, 36490.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Crack-Detection-2 in yolov8:: 100%|| 10022/10022 [00:01<00:00, 5979.49it/s]\n"
     ]
    }
   ],
   "source": [
    "#cracks and dents detection\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"ta-8behn\").project(\"crack-detection-ypnwo\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1091134,
     "status": "ok",
     "timestamp": 1717340920809,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "6QqHBRALbA5m",
    "outputId": "eeeec1f2-d850-416c-c5a0-703af47235c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/Crack-Detection-2/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/Crack-Detection-2/train/labels... 4122 images, 0 backgrounds, 0 corrupt: 100% 4122/4122 [00:01<00:00, 2159.03it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/Crack-Detection-2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Crack-Detection-2/valid/labels... 589 images, 0 backgrounds, 0 corrupt: 100% 589/589 [00:00<00:00, 690.64it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/Crack-Detection-2/valid/labels.cache\n",
      "Plotting labels to runs/detect/train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.23G      1.424      2.092      1.874         10        640: 100% 258/258 [01:39<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:08<00:00,  2.36it/s]\n",
      "                   all        589        629      0.585      0.666       0.61      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      4.18G      1.386      1.352      1.833         10        640: 100% 258/258 [01:35<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:08<00:00,  2.28it/s]\n",
      "                   all        589        629       0.61      0.474      0.552      0.277\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      4.13G        1.3      1.225      1.742         10        640: 100% 258/258 [01:35<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:06<00:00,  2.77it/s]\n",
      "                   all        589        629      0.848      0.684      0.825      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      4.17G       1.19      1.086       1.66         10        640: 100% 258/258 [01:33<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:10<00:00,  1.82it/s]\n",
      "                   all        589        629      0.849      0.831      0.889      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      4.15G      1.115     0.9727       1.58         11        640: 100% 258/258 [01:35<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.44it/s]\n",
      "                   all        589        629      0.868      0.812      0.904      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      4.17G      1.063     0.9007      1.526         10        640: 100% 258/258 [01:33<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.60it/s]\n",
      "                   all        589        629      0.825      0.878      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      4.15G     0.9871     0.7961      1.466         11        640: 100% 258/258 [01:34<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:10<00:00,  1.82it/s]\n",
      "                   all        589        629      0.934      0.851      0.939       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      4.17G     0.9397     0.7219      1.418         10        640: 100% 258/258 [01:33<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.63it/s]\n",
      "                   all        589        629      0.943      0.894      0.957      0.696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      4.14G     0.9119     0.6643      1.392         10        640: 100% 258/258 [01:35<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.57it/s]\n",
      "                   all        589        629      0.933      0.912      0.965      0.719\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      4.17G     0.8432     0.6097      1.338         12        640: 100% 258/258 [01:33<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:09<00:00,  1.97it/s]\n",
      "                   all        589        629      0.936      0.914      0.966      0.743\n",
      "\n",
      "10 epochs completed in 0.292 hours.\n",
      "Optimizer stripped from runs/detect/train2/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train2/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train2/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:11<00:00,  1.72it/s]\n",
      "                   all        589        629      0.936      0.914      0.965      0.743\n",
      "Speed: 0.3ms preprocess, 4.8ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlAmJ-JTbi_n"
   },
   "outputs": [],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True project=/content/datasets/runs name=cracks\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHnjGJfZpllt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MAM2f06plo7"
   },
   "outputs": [],
   "source": [
    "#fights detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4093,
     "status": "ok",
     "timestamp": 1717344098760,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "4npwQkn_plsD",
    "outputId": "e02fc64e-cd44-4de2-fd74-9107067d3376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in gisc-1 to yolov8:: 100%|| 35074/35074 [00:01<00:00, 33238.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to gisc-1 in yolov8:: 100%|| 1616/1616 [00:00<00:00, 6909.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"mslee\").project(\"gisc\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1812608,
     "status": "ok",
     "timestamp": 1717346328652,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "M7mRRemopous",
    "outputId": "d0618803-edb8-45b2-a828-f281fa4e297e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/gisc-1/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train8\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train8', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/gisc-1/train/labels.cache... 636 images, 0 backgrounds, 0 corrupt: 100% 636/636 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/gisc-1/valid/labels.cache... 81 images, 0 backgrounds, 0 corrupt: 100% 81/81 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train8/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train8\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100       4.2G      1.583      3.222      1.712         26        640: 100% 40/40 [00:19<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.33it/s]\n",
      "                   all         81         92      0.105      0.272     0.0716     0.0265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100      4.27G      1.818      2.329      1.864         23        640: 100% 40/40 [00:16<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.82it/s]\n",
      "                   all         81         92     0.0498      0.435     0.0368     0.0119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100      4.14G      1.926      2.407      1.978         24        640: 100% 40/40 [00:16<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.62it/s]\n",
      "                   all         81         92    0.00409      0.685     0.0037    0.00124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100      4.14G      1.987      2.513       2.04         28        640: 100% 40/40 [00:16<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.61it/s]\n",
      "                   all         81         92     0.0907      0.326     0.0735     0.0225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      4.15G      1.914      2.384       1.97         38        640: 100% 40/40 [00:14<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.27it/s]\n",
      "                   all         81         92     0.0473      0.109     0.0384     0.0118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100      4.14G      1.941      2.376      2.005         27        640: 100% 40/40 [00:13<00:00,  3.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.67it/s]\n",
      "                   all         81         92    0.00416      0.261    0.00361     0.0012\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100      4.14G      1.841      2.338      1.954         27        640: 100% 40/40 [00:13<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.68it/s]\n",
      "                   all         81         92      0.212      0.231      0.155     0.0615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      4.14G      1.821      2.264      1.951         21        640: 100% 40/40 [00:14<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.76it/s]\n",
      "                   all         81         92      0.161      0.207       0.11     0.0388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100      4.14G      1.767      2.194      1.905         31        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.68it/s]\n",
      "                   all         81         92      0.214      0.261      0.123     0.0364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100      4.15G       1.77      2.224      1.902         26        640: 100% 40/40 [00:16<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.66it/s]\n",
      "                   all         81         92      0.226      0.304      0.197     0.0725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100      4.15G      1.779      2.213      1.892         21        640: 100% 40/40 [00:15<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.80it/s]\n",
      "                   all         81         92        0.3      0.312      0.222     0.0841\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100      4.14G      1.717      2.151      1.834         35        640: 100% 40/40 [00:14<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.53it/s]\n",
      "                   all         81         92      0.209      0.315      0.188     0.0766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100      4.14G      1.716      2.126      1.836         19        640: 100% 40/40 [00:12<00:00,  3.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.42it/s]\n",
      "                   all         81         92      0.365      0.288      0.219     0.0846\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100      4.14G      1.693      2.074      1.829         31        640: 100% 40/40 [00:13<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         81         92      0.281        0.5      0.285      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100      4.14G      1.614       1.97       1.73         20        640: 100% 40/40 [00:14<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.56it/s]\n",
      "                   all         81         92      0.348      0.272      0.251     0.0997\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100      4.13G      1.664      1.987      1.778         32        640: 100% 40/40 [00:16<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.90it/s]\n",
      "                   all         81         92      0.299      0.424        0.3      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100      4.14G       1.62      1.942      1.754         34        640: 100% 40/40 [00:16<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.32it/s]\n",
      "                   all         81         92      0.148      0.381      0.122     0.0491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100      4.14G      1.598      1.908      1.731         25        640: 100% 40/40 [00:16<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.84it/s]\n",
      "                   all         81         92      0.326      0.348      0.277      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100      4.14G      1.608      1.917      1.753         21        640: 100% 40/40 [00:14<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.51it/s]\n",
      "                   all         81         92      0.264       0.37      0.254     0.0948\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100      4.13G      1.555      1.862      1.705         31        640: 100% 40/40 [00:12<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.61it/s]\n",
      "                   all         81         92      0.361      0.467      0.331       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100      4.14G      1.518      1.755      1.677         30        640: 100% 40/40 [00:13<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.68it/s]\n",
      "                   all         81         92      0.373      0.356      0.289      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100      4.14G      1.573      1.819      1.684         32        640: 100% 40/40 [00:15<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.47it/s]\n",
      "                   all         81         92      0.433      0.315      0.338      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100      4.14G      1.563      1.875      1.685         26        640: 100% 40/40 [00:15<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.46it/s]\n",
      "                   all         81         92      0.321        0.5      0.323      0.146\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100      4.14G      1.486      1.786      1.654         29        640: 100% 40/40 [00:15<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.51it/s]\n",
      "                   all         81         92      0.418       0.38      0.394      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100      4.14G      1.512      1.725      1.644         30        640: 100% 40/40 [00:15<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
      "                   all         81         92      0.403      0.446      0.395      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100      4.14G      1.486      1.697      1.613         21        640: 100% 40/40 [00:14<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.41it/s]\n",
      "                   all         81         92      0.412      0.467      0.457      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100      4.14G      1.516      1.747      1.659         30        640: 100% 40/40 [00:12<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.56it/s]\n",
      "                   all         81         92      0.288       0.44      0.301      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100      4.13G      1.467      1.721      1.616         27        640: 100% 40/40 [00:14<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.52it/s]\n",
      "                   all         81         92      0.422      0.478      0.453       0.23\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100      4.14G      1.408      1.624      1.611         23        640: 100% 40/40 [00:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.73it/s]\n",
      "                   all         81         92      0.423      0.457      0.442      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100      4.15G      1.485      1.699      1.633         29        640: 100% 40/40 [00:15<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.58it/s]\n",
      "                   all         81         92      0.588      0.435      0.465      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100      4.14G      1.427       1.66      1.603         21        640: 100% 40/40 [00:16<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.47it/s]\n",
      "                   all         81         92      0.491      0.391      0.465      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100      4.15G      1.445      1.675      1.598         22        640: 100% 40/40 [00:16<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.16it/s]\n",
      "                   all         81         92      0.491      0.457      0.467      0.249\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100      4.13G      1.418      1.648      1.597         27        640: 100% 40/40 [00:14<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.38it/s]\n",
      "                   all         81         92      0.498      0.446       0.47      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100      4.14G      1.394      1.567      1.567         29        640: 100% 40/40 [00:13<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.51it/s]\n",
      "                   all         81         92       0.56      0.522      0.518      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100      4.14G      1.392       1.55      1.571         26        640: 100% 40/40 [00:13<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
      "                   all         81         92      0.603      0.446      0.492      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100      4.16G      1.397      1.569      1.575         22        640: 100% 40/40 [00:14<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.57it/s]\n",
      "                   all         81         92      0.494        0.5      0.439      0.238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100      4.15G      1.332      1.553      1.547         24        640: 100% 40/40 [00:16<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.67it/s]\n",
      "                   all         81         92       0.48       0.62      0.555      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100      4.14G      1.353      1.497      1.554         28        640: 100% 40/40 [00:16<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.54it/s]\n",
      "                   all         81         92      0.473      0.526      0.457      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100      4.14G      1.335      1.506      1.537         25        640: 100% 40/40 [00:16<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.53it/s]\n",
      "                   all         81         92      0.608      0.446      0.499      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100      4.14G       1.33      1.464      1.499         32        640: 100% 40/40 [00:14<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.38it/s]\n",
      "                   all         81         92       0.55      0.531      0.528      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100      4.14G      1.316      1.468      1.506         17        640: 100% 40/40 [00:13<00:00,  3.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.60it/s]\n",
      "                   all         81         92      0.618      0.522      0.533      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100      4.15G      1.334      1.458      1.517         31        640: 100% 40/40 [00:13<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.76it/s]\n",
      "                   all         81         92      0.649      0.467      0.563      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100      4.15G      1.295       1.49      1.502         27        640: 100% 40/40 [00:13<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.29it/s]\n",
      "                   all         81         92      0.655      0.522      0.562      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100      4.14G       1.31      1.467      1.497         19        640: 100% 40/40 [00:15<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.81it/s]\n",
      "                   all         81         92      0.564      0.562      0.551      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100      4.14G      1.308      1.361        1.5         26        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.64it/s]\n",
      "                   all         81         92      0.578      0.489      0.532      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100      4.15G      1.248      1.343      1.459         28        640: 100% 40/40 [00:16<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.70it/s]\n",
      "                   all         81         92      0.507      0.478      0.457      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100      4.14G      1.305       1.37      1.484         33        640: 100% 40/40 [00:16<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.33it/s]\n",
      "                   all         81         92      0.573       0.57      0.555      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/100      4.13G      1.269      1.349      1.458         34        640: 100% 40/40 [00:13<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.41it/s]\n",
      "                   all         81         92      0.444      0.587      0.487      0.247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100      4.14G      1.246      1.318      1.451         21        640: 100% 40/40 [00:12<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.68it/s]\n",
      "                   all         81         92       0.59      0.484      0.536      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100      4.14G      1.254      1.319      1.455         30        640: 100% 40/40 [00:14<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.33it/s]\n",
      "                   all         81         92      0.583      0.489      0.556      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100      4.14G      1.209      1.272      1.415         22        640: 100% 40/40 [00:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.60it/s]\n",
      "                   all         81         92      0.531      0.565      0.542      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/100      4.14G      1.226      1.271      1.428         21        640: 100% 40/40 [00:16<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.60it/s]\n",
      "                   all         81         92       0.57      0.609      0.571      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/100      4.14G      1.191      1.232      1.408         18        640: 100% 40/40 [00:16<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.57it/s]\n",
      "                   all         81         92      0.555        0.5      0.533      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/100      4.15G      1.217      1.222      1.427         23        640: 100% 40/40 [00:15<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.94it/s]\n",
      "                   all         81         92       0.69        0.5      0.608      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/100      4.14G      1.193      1.218      1.417         30        640: 100% 40/40 [00:13<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.26it/s]\n",
      "                   all         81         92      0.516      0.565      0.552      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/100      4.15G      1.144      1.191      1.384         24        640: 100% 40/40 [00:13<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.86it/s]\n",
      "                   all         81         92      0.614      0.572      0.614      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/100      4.14G      1.195      1.233       1.41         36        640: 100% 40/40 [00:14<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.93it/s]\n",
      "                   all         81         92       0.61       0.62      0.653      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/100      4.14G      1.166      1.163      1.399         20        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.44it/s]\n",
      "                   all         81         92       0.63      0.556      0.604      0.334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/100      4.14G       1.13      1.161      1.349         26        640: 100% 40/40 [00:15<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.52it/s]\n",
      "                   all         81         92      0.712      0.543        0.6      0.331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/100      4.14G      1.108      1.132      1.362         30        640: 100% 40/40 [00:16<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.73it/s]\n",
      "                   all         81         92      0.536      0.511       0.56      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/100      4.15G       1.13      1.156      1.378         21        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.15it/s]\n",
      "                   all         81         92      0.597      0.641      0.619      0.347\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/100      4.14G       1.14      1.118      1.383         34        640: 100% 40/40 [00:13<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.33it/s]\n",
      "                   all         81         92      0.611      0.565      0.575      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/100      4.14G      1.149      1.125      1.378         25        640: 100% 40/40 [00:13<00:00,  3.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.77it/s]\n",
      "                   all         81         92      0.582      0.554      0.557      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/100      4.14G      1.079      1.087      1.346         34        640: 100% 40/40 [00:13<00:00,  2.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         81         92      0.591      0.554       0.59      0.326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/100      4.15G      1.137      1.097      1.382         24        640: 100% 40/40 [00:15<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.76it/s]\n",
      "                   all         81         92      0.569      0.576      0.564      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/100      4.14G      1.075      1.103      1.347         27        640: 100% 40/40 [00:16<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.73it/s]\n",
      "                   all         81         92      0.469      0.644      0.596      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/100      4.14G      1.043      1.016      1.315         32        640: 100% 40/40 [00:16<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.88it/s]\n",
      "                   all         81         92      0.705      0.522      0.578      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/100      4.14G      1.074      1.036      1.325         32        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.83it/s]\n",
      "                   all         81         92      0.555      0.587      0.565      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/100      4.14G      1.051      1.003      1.315         25        640: 100% 40/40 [00:15<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.29it/s]\n",
      "                   all         81         92      0.568      0.663      0.632      0.327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/100      4.14G      1.051      1.021      1.302         19        640: 100% 40/40 [00:13<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.54it/s]\n",
      "                   all         81         92      0.554       0.58      0.525      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/100      4.14G      1.053     0.9957        1.3         26        640: 100% 40/40 [00:12<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.46it/s]\n",
      "                   all         81         92      0.589      0.686      0.677      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/100      4.14G       1.05     0.9808      1.314         23        640: 100% 40/40 [00:14<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.21it/s]\n",
      "                   all         81         92      0.622      0.555       0.61      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/100      4.14G      1.019     0.9603      1.277         26        640: 100% 40/40 [00:16<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.77it/s]\n",
      "                   all         81         92      0.566       0.63      0.598      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/100      4.14G      1.001     0.9261      1.262         34        640: 100% 40/40 [00:16<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.71it/s]\n",
      "                   all         81         92       0.65        0.5      0.586      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/100      4.14G      1.029     0.9578      1.282         24        640: 100% 40/40 [00:16<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.73it/s]\n",
      "                   all         81         92       0.71      0.532      0.627      0.371\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/100      4.14G       1.01     0.9588      1.282         26        640: 100% 40/40 [00:15<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.52it/s]\n",
      "                   all         81         92      0.657      0.562      0.591      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/100      4.14G      1.008      0.941       1.28         25        640: 100% 40/40 [00:14<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.36it/s]\n",
      "                   all         81         92      0.666      0.565      0.642       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/100      4.14G     0.9537     0.9233      1.254         28        640: 100% 40/40 [00:13<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.61it/s]\n",
      "                   all         81         92      0.735      0.576      0.655      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/100      4.15G      0.974     0.9089       1.26         27        640: 100% 40/40 [00:14<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.66it/s]\n",
      "                   all         81         92      0.654      0.595      0.631      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/100      4.14G     0.9721     0.8829      1.245         37        640: 100% 40/40 [00:15<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.43it/s]\n",
      "                   all         81         92      0.682      0.583       0.63      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/100      4.14G     0.9292     0.8627      1.245         32        640: 100% 40/40 [00:16<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.74it/s]\n",
      "                   all         81         92      0.681      0.587       0.66      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/100      4.14G     0.9242     0.8581      1.228         30        640: 100% 40/40 [00:16<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.47it/s]\n",
      "                   all         81         92      0.759      0.617      0.674      0.356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/100      4.14G      0.927     0.8606      1.226         30        640: 100% 40/40 [00:16<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         81         92      0.648       0.62       0.68      0.375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/100      4.14G     0.9392     0.8729      1.247         26        640: 100% 40/40 [00:14<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.62it/s]\n",
      "                   all         81         92      0.741      0.598      0.675      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/100      4.14G      0.911     0.8414      1.222         22        640: 100% 40/40 [00:13<00:00,  3.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.69it/s]\n",
      "                   all         81         92      0.774      0.576      0.665      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/100      4.15G       0.91       0.85      1.209         23        640: 100% 40/40 [00:13<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.63it/s]\n",
      "                   all         81         92      0.615       0.63      0.681       0.37\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/100      4.13G      0.913     0.8317      1.212         23        640: 100% 40/40 [00:15<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.56it/s]\n",
      "                   all         81         92      0.701      0.598      0.653      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/100      4.14G     0.8821     0.7977      1.193         25        640: 100% 40/40 [00:15<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.67it/s]\n",
      "                   all         81         92      0.724      0.565      0.674      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/100      4.14G     0.8873     0.8134       1.21         23        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.64it/s]\n",
      "                   all         81         92      0.792      0.538      0.682      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/100      4.14G     0.8853     0.8256      1.211         26        640: 100% 40/40 [00:17<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.58it/s]\n",
      "                   all         81         92      0.726      0.576      0.666      0.397\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/100      4.14G     0.7617     0.6852       1.13         13        640: 100% 40/40 [00:17<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.80it/s]\n",
      "                   all         81         92      0.784      0.598      0.677      0.389\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/100      4.14G     0.7707     0.6332      1.133         12        640: 100% 40/40 [00:14<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.43it/s]\n",
      "                   all         81         92      0.781      0.587      0.687      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/100      4.14G     0.7287     0.6024      1.123         13        640: 100% 40/40 [00:12<00:00,  3.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.77it/s]\n",
      "                   all         81         92      0.737      0.609      0.725      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/100      4.14G      0.719     0.5787      1.117         13        640: 100% 40/40 [00:13<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.92it/s]\n",
      "                   all         81         92      0.694      0.652      0.702      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/100      4.14G      0.714     0.5726       1.11         13        640: 100% 40/40 [00:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.87it/s]\n",
      "                   all         81         92      0.727       0.63      0.693      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/100      4.14G     0.7165      0.557      1.103         14        640: 100% 40/40 [00:16<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.81it/s]\n",
      "                   all         81         92      0.763      0.561      0.671      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/100      4.14G     0.7077     0.5391      1.082         13        640: 100% 40/40 [00:15<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         81         92      0.764      0.563       0.68      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/100      4.14G     0.6952     0.5508      1.091         16        640: 100% 40/40 [00:13<00:00,  3.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.51it/s]\n",
      "                   all         81         92       0.76      0.586      0.686      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/100      4.14G     0.6914     0.5481      1.095         12        640: 100% 40/40 [00:12<00:00,  3.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.79it/s]\n",
      "                   all         81         92      0.696       0.62      0.684      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/100      4.14G     0.6761     0.5256      1.079         15        640: 100% 40/40 [00:15<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:00<00:00,  3.01it/s]\n",
      "                   all         81         92       0.76      0.609      0.683      0.383\n",
      "\n",
      "100 epochs completed in 0.495 hours.\n",
      "Optimizer stripped from runs/detect/train8/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train8/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train8/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.45it/s]\n",
      "                   all         81         92      0.693      0.652      0.702      0.402\n",
      "Speed: 0.3ms preprocess, 4.7ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train8\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=100 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJMsBbPgqY6Q"
   },
   "outputs": [],
   "source": [
    "## fire and smoke detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3ainjsK4m2B"
   },
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"my-space-3zzwr\").project(\"fire-smoke-detection-odvk6\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjpdVlIe4sCn"
   },
   "outputs": [],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=4 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40rmve4_4slM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1xSYuAS4tLh"
   },
   "outputs": [],
   "source": [
    "## climber detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4105,
     "status": "ok",
     "timestamp": 1717347547540,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "QGGm9xNC4wyX",
    "outputId": "c5290592-d347-44d9-aea1-8fe5f3c8f9cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in climbing-detection-1 to yolov8:: 100%|| 31510/31510 [00:00<00:00, 31544.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to climbing-detection-1 in yolov8:: 100%|| 1036/1036 [00:00<00:00, 6067.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"min-tang-ugcdi\").project(\"climbing-detection\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 561031,
     "status": "ok",
     "timestamp": 1717348536799,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "1rb5ZZru4-cH",
    "outputId": "91900067-8a0e-47f2-91ca-502591836f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/climbing-detection-1/data.yaml, epochs=40, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train10\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train10', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/climbing-detection-1/train/labels.cache... 488 images, 0 backgrounds, 0 corrupt: 100% 488/488 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/climbing-detection-1/valid/labels.cache... 19 images, 0 backgrounds, 0 corrupt: 100% 19/19 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train10/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train10\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/40      4.22G      1.763      3.118      2.038         14        640: 100% 31/31 [00:15<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.38it/s]\n",
      "                   all         19         23      0.398      0.478       0.36      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/40      4.13G       1.78      1.814      1.998         27        640: 100% 31/31 [00:09<00:00,  3.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.12it/s]\n",
      "                   all         19         23      0.081      0.565     0.0614     0.0172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/40      4.14G       1.85      1.885      2.015         17        640: 100% 31/31 [00:13<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.68it/s]\n",
      "                   all         19         23       0.25      0.174      0.134       0.02\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/40      4.15G      1.853      1.924      2.025         16        640: 100% 31/31 [00:10<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.87it/s]\n",
      "                   all         19         23     0.0107     0.0435    0.00231   0.000427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/40      4.27G      1.862      1.856      2.056         17        640: 100% 31/31 [00:09<00:00,  3.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.82it/s]\n",
      "                   all         19         23     0.0271     0.0633      0.011    0.00297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/40      4.14G       1.84      1.865      2.012         17        640: 100% 31/31 [00:13<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.96it/s]\n",
      "                   all         19         23      0.134      0.217     0.0574     0.0122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/40      4.13G      1.769      1.745      1.939         22        640: 100% 31/31 [00:10<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.27it/s]\n",
      "                   all         19         23      0.249      0.261      0.269     0.0628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/40      4.14G      1.776       1.81      1.969         15        640: 100% 31/31 [00:10<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.47it/s]\n",
      "                   all         19         23      0.163      0.348      0.153     0.0505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/40      4.11G       1.76      1.701      1.953         28        640: 100% 31/31 [00:12<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.54it/s]\n",
      "                   all         19         23      0.241      0.304      0.218     0.0571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/40      4.14G      1.718      1.667      1.893         23        640: 100% 31/31 [00:09<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.19it/s]\n",
      "                   all         19         23      0.531      0.565      0.467      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/40      4.14G       1.66      1.577      1.871         23        640: 100% 31/31 [00:11<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.72it/s]\n",
      "                   all         19         23      0.605      0.478      0.469      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/40      4.14G      1.721      1.587      1.906         20        640: 100% 31/31 [00:12<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.90it/s]\n",
      "                   all         19         23      0.294      0.522      0.248     0.0589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/40      4.27G      1.658      1.643      1.877         21        640: 100% 31/31 [00:09<00:00,  3.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.56it/s]\n",
      "                   all         19         23      0.452      0.609      0.572      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/40      4.14G       1.57      1.484        1.8         19        640: 100% 31/31 [00:12<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.05it/s]\n",
      "                   all         19         23      0.493      0.435      0.341     0.0661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/40      4.14G      1.607      1.489      1.808         22        640: 100% 31/31 [00:12<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.12it/s]\n",
      "                   all         19         23      0.754      0.522      0.617       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/40      4.13G       1.57      1.468       1.79         18        640: 100% 31/31 [00:09<00:00,  3.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.67it/s]\n",
      "                   all         19         23      0.533      0.826      0.691      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/40      4.27G      1.554       1.39       1.76         20        640: 100% 31/31 [00:12<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.59it/s]\n",
      "                   all         19         23      0.633      0.696      0.715      0.275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/40      4.15G      1.584      1.417      1.769         24        640: 100% 31/31 [00:11<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.04it/s]\n",
      "                   all         19         23      0.629      0.442       0.54      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/40      4.14G      1.528      1.377      1.703         25        640: 100% 31/31 [00:09<00:00,  3.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.97it/s]\n",
      "                   all         19         23      0.798      0.688       0.77      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/40      4.14G      1.501      1.336      1.704         22        640: 100% 31/31 [00:13<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.48it/s]\n",
      "                   all         19         23      0.786      0.637      0.737      0.307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/40      4.11G      1.477      1.285      1.717         21        640: 100% 31/31 [00:11<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.89it/s]\n",
      "                   all         19         23      0.706      0.826      0.795      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/40      4.14G       1.46      1.253      1.691         23        640: 100% 31/31 [00:09<00:00,  3.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.50it/s]\n",
      "                   all         19         23      0.696      0.696      0.734      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/40      4.14G      1.412      1.182      1.628         22        640: 100% 31/31 [00:13<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.38it/s]\n",
      "                   all         19         23       0.78      0.652      0.797      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/40      4.14G      1.423      1.223      1.664         20        640: 100% 31/31 [00:10<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         19         23      0.871      0.696      0.843      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/40      4.11G      1.403      1.169      1.643         18        640: 100% 31/31 [00:10<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.10it/s]\n",
      "                   all         19         23      0.698      0.803      0.775      0.363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/40      4.15G      1.351      1.133      1.606         17        640: 100% 31/31 [00:13<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.66it/s]\n",
      "                   all         19         23      0.662      0.683      0.711      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/40      4.13G       1.36      1.121      1.586         18        640: 100% 31/31 [00:09<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.05it/s]\n",
      "                   all         19         23      0.719      0.557      0.686      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/40      4.13G      1.338      1.088      1.574         17        640: 100% 31/31 [00:11<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.08it/s]\n",
      "                   all         19         23      0.684      0.739      0.761      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/40      4.12G      1.312      1.071      1.545         20        640: 100% 31/31 [00:12<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         19         23      0.776      0.752      0.808      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/40      4.14G      1.302      1.081      1.548         20        640: 100% 31/31 [00:09<00:00,  3.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.29it/s]\n",
      "                   all         19         23      0.769      0.725      0.805      0.359\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/40      4.14G       1.26     0.8862      1.621          9        640: 100% 31/31 [00:13<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.36it/s]\n",
      "                   all         19         23      0.807      0.609      0.766      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/40      4.14G       1.22     0.7743      1.601         10        640: 100% 31/31 [00:12<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.68it/s]\n",
      "                   all         19         23      0.618      0.844       0.76      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/40      4.12G      1.191     0.7364      1.571         10        640: 100% 31/31 [00:08<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.30it/s]\n",
      "                   all         19         23       0.83      0.652      0.766      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/40      4.14G      1.152     0.7254      1.534         11        640: 100% 31/31 [00:12<00:00,  2.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.10it/s]\n",
      "                   all         19         23      0.728      0.813      0.797      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/40      4.14G      1.131     0.6738      1.515          9        640: 100% 31/31 [00:11<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.23it/s]\n",
      "                   all         19         23      0.798      0.739      0.807      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/40      4.13G      1.124     0.6727      1.529          8        640: 100% 31/31 [00:08<00:00,  3.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.53it/s]\n",
      "                   all         19         23      0.671       0.87      0.836      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/40      4.27G      1.081     0.6487      1.463          8        640: 100% 31/31 [00:13<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.65it/s]\n",
      "                   all         19         23      0.835       0.66      0.819      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/40      4.15G      1.034     0.6453      1.447          8        640: 100% 31/31 [00:09<00:00,  3.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.47it/s]\n",
      "                   all         19         23      0.736       0.85      0.856      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/40      4.13G      1.041     0.6224      1.439         14        640: 100% 31/31 [00:11<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.79it/s]\n",
      "                   all         19         23      0.658       0.87      0.803      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/40      4.14G      1.007     0.6034      1.419          8        640: 100% 31/31 [00:11<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.12it/s]\n",
      "                   all         19         23      0.667      0.869      0.818      0.441\n",
      "\n",
      "40 epochs completed in 0.149 hours.\n",
      "Optimizer stripped from runs/detect/train10/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train10/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train10/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.98it/s]\n",
      "                   all         19         23      0.728      0.814      0.797      0.455\n",
      "Speed: 0.2ms preprocess, 5.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train10\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=40 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7691,
     "status": "ok",
     "timestamp": 1717393205929,
     "user": {
      "displayName": "afith 234",
      "userId": "04481233657332223077"
     },
     "user_tz": -330
    },
    "id": "Hqqm2LXs5Z7D",
    "outputId": "2b159b74-5952-44aa-e639-427c1fde4f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.28, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in firesmoke-3 to yolov8:: 100%|| 58482/58482 [00:01<00:00, 57904.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to firesmoke-3 in yolov8:: 100%|| 3556/3556 [00:00<00:00, 7233.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"gradproject-b3qu8\").project(\"firesmoke-qedaj\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1105376,
     "status": "ok",
     "timestamp": 1717394442315,
     "user": {
      "displayName": "afith 234",
      "userId": "04481233657332223077"
     },
     "user_tz": -330
    },
    "id": "dPY7EBX5ghgy",
    "outputId": "f1b0e451-0ade-4984-dcaa-078f38efe601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/firesmoke-3/data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100% 755k/755k [00:00<00:00, 23.0MB/s]\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11136374 parameters, 11136358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100% 6.23M/6.23M [00:00<00:00, 130MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/firesmoke-3/train/labels... 1244 images, 0 backgrounds, 0 corrupt: 100% 1244/1244 [00:00<00:00, 2058.64it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/firesmoke-3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/firesmoke-3/valid/labels... 357 images, 0 backgrounds, 0 corrupt: 100% 357/357 [00:00<00:00, 1274.75it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/firesmoke-3/valid/labels.cache\n",
      "Plotting labels to runs/detect/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/30      4.26G      2.088      2.957      2.057         76        640: 100% 78/78 [00:38<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:05<00:00,  2.24it/s]\n",
      "                   all        357        703      0.249      0.217      0.154     0.0474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/30      4.17G      2.138      2.529      2.104         43        640: 100% 78/78 [00:31<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.88it/s]\n",
      "                   all        357        703       0.11      0.117     0.0387     0.0109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/30      4.19G      2.137      2.544      2.109         40        640: 100% 78/78 [00:29<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:05<00:00,  2.28it/s]\n",
      "                   all        357        703      0.203       0.18      0.131     0.0407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/30      4.16G      2.095       2.51      2.082         36        640: 100% 78/78 [00:27<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.78it/s]\n",
      "                   all        357        703      0.504      0.199      0.205      0.074\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/30      4.17G      2.065      2.426      2.029         46        640: 100% 78/78 [00:26<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:05<00:00,  2.16it/s]\n",
      "                   all        357        703      0.286      0.364       0.26     0.0958\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/30      4.16G      2.023      2.343      2.008         52        640: 100% 78/78 [00:28<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.71it/s]\n",
      "                   all        357        703      0.351       0.36      0.318      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/30      4.16G      2.004      2.303      1.999         39        640: 100% 78/78 [00:29<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.59it/s]\n",
      "                   all        357        703      0.486      0.344      0.359       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/30      4.13G       1.96      2.236      1.961         47        640: 100% 78/78 [00:31<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:03<00:00,  3.03it/s]\n",
      "                   all        357        703      0.448      0.424      0.385      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/30      4.22G      1.978      2.251      1.962         55        640: 100% 78/78 [00:30<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.85it/s]\n",
      "                   all        357        703       0.38      0.384      0.317      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/30      4.16G      1.944      2.171      1.939         63        640: 100% 78/78 [00:28<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.94it/s]\n",
      "                   all        357        703      0.515      0.437      0.431      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/30      4.16G      1.904      2.091      1.906         56        640: 100% 78/78 [00:26<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.95it/s]\n",
      "                   all        357        703      0.513      0.484      0.476      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/30      4.16G      1.921      2.096      1.907         39        640: 100% 78/78 [00:26<00:00,  2.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.65it/s]\n",
      "                   all        357        703      0.447      0.495      0.458      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/30      4.19G      1.865      1.998      1.864         38        640: 100% 78/78 [00:28<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:03<00:00,  3.11it/s]\n",
      "                   all        357        703      0.572      0.495      0.514      0.218\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/30      4.16G      1.844      2.008      1.876         55        640: 100% 78/78 [00:31<00:00,  2.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.80it/s]\n",
      "                   all        357        703       0.45      0.481      0.445      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/30      4.19G       1.83      1.931      1.837         40        640: 100% 78/78 [00:28<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.99it/s]\n",
      "                   all        357        703      0.597      0.497      0.534       0.23\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/30      4.15G      1.831      1.915      1.847         31        640: 100% 78/78 [00:29<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.95it/s]\n",
      "                   all        357        703      0.597      0.475      0.513      0.215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/30      4.18G      1.797      1.941      1.836         33        640: 100% 78/78 [00:29<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.59it/s]\n",
      "                   all        357        703      0.579      0.524      0.534      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/30      4.16G      1.802      1.835        1.8         29        640: 100% 78/78 [00:27<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.76it/s]\n",
      "                   all        357        703      0.685      0.522      0.581      0.255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/30      4.19G       1.78      1.817      1.818         42        640: 100% 78/78 [00:26<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:05<00:00,  2.07it/s]\n",
      "                   all        357        703       0.62       0.55      0.563      0.248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/30      4.17G      1.739      1.756      1.766         28        640: 100% 78/78 [00:27<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.91it/s]\n",
      "                   all        357        703      0.692      0.554      0.603      0.267\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/30      4.17G      1.811      1.757      1.873         15        640: 100% 78/78 [00:31<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.93it/s]\n",
      "                   all        357        703      0.659      0.559      0.607      0.272\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/30      4.15G      1.798      1.683       1.85         18        640: 100% 78/78 [00:25<00:00,  3.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.84it/s]\n",
      "                   all        357        703      0.634      0.587      0.602      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/30      4.16G      1.742      1.601       1.82         20        640: 100% 78/78 [00:27<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:03<00:00,  3.21it/s]\n",
      "                   all        357        703       0.67      0.596       0.63      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/30      4.16G      1.721       1.58       1.82         20        640: 100% 78/78 [00:28<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.48it/s]\n",
      "                   all        357        703      0.696      0.609      0.638      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/30      4.16G      1.685      1.516      1.787         28        640: 100% 78/78 [00:25<00:00,  3.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.80it/s]\n",
      "                   all        357        703      0.736      0.586      0.635      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/30      4.13G      1.679      1.468      1.765         27        640: 100% 78/78 [00:27<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:05<00:00,  2.04it/s]\n",
      "                   all        357        703      0.699      0.608      0.646      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/30      4.15G      1.649      1.437       1.75         17        640: 100% 78/78 [00:28<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:03<00:00,  3.11it/s]\n",
      "                   all        357        703      0.721      0.613       0.66      0.303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/30      4.14G      1.595      1.369      1.703         22        640: 100% 78/78 [00:30<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:07<00:00,  1.71it/s]\n",
      "                   all        357        703      0.712      0.606      0.663      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/30      4.15G      1.601       1.36      1.715         24        640: 100% 78/78 [00:26<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.92it/s]\n",
      "                   all        357        703      0.746       0.62       0.68      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/30      4.13G      1.593      1.312      1.697         29        640: 100% 78/78 [00:27<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.93it/s]\n",
      "                   all        357        703      0.788      0.623       0.69      0.328\n",
      "\n",
      "30 epochs completed in 0.296 hours.\n",
      "Optimizer stripped from runs/detect/train3/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train3/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train3/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.28  Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:07<00:00,  1.51it/s]\n",
      "                   all        357        703      0.768      0.637      0.691      0.328\n",
      "                  fire        264        342      0.804      0.787      0.825      0.415\n",
      "                 smoke        221        361      0.732      0.488      0.557       0.24\n",
      "Speed: 0.4ms preprocess, 5.6ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=30 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XwRjxRKsr6fx"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Set ENV Variables (place before imports)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# reduce CPU utilization during training\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplorer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Explorer\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NAS, RTDETR, SAM, YOLO, FastSAM, YOLOWorld\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASSETS, SETTINGS\n",
      "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO , AGPL-3.0 license\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dataloader, build_grounding, build_yolo_dataset, load_inference_source\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     ClassificationDataset,\n\u001b[0;32m      7\u001b[0m     GroundingDataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     YOLOMultiModalDataset,\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsutil\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FORMATS_HELP_MSG, HELP_URL, IMG_FORMATS\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_CFG, LOCAL_RANK, LOGGER, NUM_THREADS, TQDM\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def predict_accident(image_url):\n",
    "    # Load the trained model\n",
    "    model = YOLO('./realtime_accident.pt')\n",
    "    \n",
    "    # Fetch the image from the URL\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    \n",
    "    # Perform prediction\n",
    "    results = model(img)\n",
    "    \n",
    "    # Display or return results\n",
    "    results.show()  # This will display the image with predictions\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "image_url = 'https://valleycollision.com/blog/the-top-5-causes-of-car-accidents-in-the-u-s/'\n",
    "predict_accident(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi==0.108.0\n",
      "  Using cached fastapi-0.108.0-py3-none-any.whl (92 kB)\n",
      "Requirement already satisfied: uvicorn[standard] in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 2)) (0.30.6)\n",
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.38-py3-none-any.whl (896 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Collecting keras\n",
      "  Using cached keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 7)) (2.32.3)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.35.71-py3-none-any.whl (139 kB)\n",
      "Collecting dnspython\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Requirement already satisfied: python-decouple in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 10)) (3.8)\n",
      "Collecting face-recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting python-multipart\n",
      "  Using cached python_multipart-0.0.17-py3-none-any.whl (24 kB)\n",
      "Collecting roboflow\n",
      "  Using cached roboflow-1.1.49-py3-none-any.whl (80 kB)\n",
      "Collecting inference-sdk\n",
      "  Using cached inference_sdk-0.28.2-py3-none-any.whl (33 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi==0.108.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi==0.108.0->-r requirements.txt (line 1)) (2.9.2)\n",
      "Collecting starlette<0.33.0,>=0.29.0\n",
      "  Using cached starlette-0.32.0.post1-py3-none-any.whl (70 kB)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (0.4.6)\n",
      "Collecting websockets>=10.4\n",
      "  Using cached websockets-14.1-cp310-cp310-win_amd64.whl (163 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (6.0.2)\n",
      "Collecting httptools>=0.5.0\n",
      "  Using cached httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (1.0.1)\n",
      "Collecting watchfiles>=0.13\n",
      "  Using cached watchfiles-1.0.0-cp310-none-win_amd64.whl (285 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (4.66.5)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (9.0.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (10.4.0)\n",
      "Requirement already satisfied: torch!=2.4.0,>=1.8.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (2.5.1)\n",
      "Collecting matplotlib>=3.3.0\n",
      "  Using cached matplotlib-3.9.2-cp310-cp310-win_amd64.whl (7.8 MB)\n",
      "Requirement already satisfied: psutil in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (5.9.3)\n",
      "Collecting ultralytics-thop>=2.0.0\n",
      "  Using cached ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (0.20.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (1.14.1)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (1.4.3)\n",
      "Collecting h5py\n",
      "  Using cached h5py-3.12.1-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "Requirement already satisfied: rich in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->-r requirements.txt (line 5)) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->-r requirements.txt (line 5)) (0.0.8)\n",
      "Requirement already satisfied: absl-py in c:\\users\\adith\\appdata\\roaming\\python\\python310\\site-packages (from keras->-r requirements.txt (line 5)) (1.4.0)\n",
      "Collecting optree\n",
      "  Using cached optree-0.13.1-cp310-cp310-win_amd64.whl (282 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->-r requirements.txt (line 5)) (24.2)\n",
      "Collecting ml-dtypes\n",
      "  Using cached ml_dtypes-0.5.0-cp310-cp310-win_amd64.whl (211 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->-r requirements.txt (line 7)) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->-r requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->-r requirements.txt (line 7)) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->-r requirements.txt (line 7)) (1.26.10)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0\n",
      "  Using cached s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
      "Collecting botocore<1.36.0,>=1.35.71\n",
      "  Using cached botocore-1.35.71-py3-none-any.whl (13.0 MB)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from face-recognition->-r requirements.txt (line 11)) (0.3.0)\n",
      "Collecting dlib>=19.7\n",
      "  Using cached dlib-19.24.6.tar.gz (3.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting cycler\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow->-r requirements.txt (line 13)) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow->-r requirements.txt (line 13)) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow->-r requirements.txt (line 13)) (1.16.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow->-r requirements.txt (line 13)) (1.2.0)\n",
      "Collecting opencv-python-headless==4.10.0.84\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.7-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting dataclasses-json~=0.6.0\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: aiohttp<=3.10.11,>=3.9.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from inference-sdk->-r requirements.txt (line 14)) (3.10.6)\n",
      "Collecting supervision<=0.22.0,>=0.21.0\n",
      "  Using cached supervision-0.22.0-py3-none-any.whl (135 kB)\n",
      "Collecting backoff~=2.2.0\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting tensorflow-intel==2.18.0\n",
      "  Using cached tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (18.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (58.1.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (1.66.1)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting ml-dtypes\n",
      "  Using cached ml_dtypes-0.4.1-cp310-cp310-win_amd64.whl (126 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (24.3.25)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (3.20.3)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.17.0-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (6.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (22.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (2.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (1.12.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json~=0.6.0->inference-sdk->-r requirements.txt (line 14)) (3.22.0)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 3)) (3.0.9)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.55.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 3)) (2022.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.108.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.108.0->-r requirements.txt (line 1)) (2.23.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from starlette<0.33.0,>=0.29.0->fastapi==0.108.0->-r requirements.txt (line 1)) (3.6.2)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from supervision<=0.22.0,>=0.21.0->inference-sdk->-r requirements.txt (line 14)) (0.7.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (2024.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (3.16.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras->-r requirements.txt (line 5)) (2.13.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi==0.108.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (0.37.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->-r requirements.txt (line 5)) (0.1.2)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (2.1.1)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for dlib\n",
      "Failed to build dlib\n",
      "Installing collected packages: dlib, wrapt, werkzeug, websockets, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, python-multipart, optree, opt-einsum, opencv-python-headless, opencv-python, mypy-extensions, ml-dtypes, markdown, kiwisolver, jmespath, idna, httptools, h5py, google-pasta, gast, fonttools, dnspython, cycler, contourpy, backoff, astunparse, typing-inspect, tensorboard, matplotlib, face-recognition, botocore, watchfiles, ultralytics-thop, supervision, starlette, seaborn, s3transfer, keras, dataclasses-json, ultralytics, tensorflow-intel, roboflow, inference-sdk, fastapi, boto3, tensorflow\n",
      "  Running setup.py install for dlib: started\n",
      "  Running setup.py install for dlib: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "   python setup.py bdist_wheel did not run successfully.\n",
      "   exit code: 1\n",
      "  > [41 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_ext\n",
      "      \n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      \n",
      "                         CMake is not installed on your system!\n",
      "      \n",
      "          Or it is possible some broken copy of cmake is installed on your system.\n",
      "          It is unfortunately very common for python package managers to include\n",
      "          broken copies of cmake.  So if the error above this refers to some file\n",
      "          path to a cmake file inside a python or anaconda or miniconda path then you\n",
      "          should delete that broken copy of cmake from your computer.\n",
      "      \n",
      "          Instead, please get an official copy of cmake from one of these known good\n",
      "          sources of an official cmake:\n",
      "              - cmake.org (this is how windows users should get cmake)\n",
      "              - apt install cmake (for Ubuntu or Debian based systems)\n",
      "              - yum install cmake (for Redhat or CenOS based systems)\n",
      "      \n",
      "          On a linux machine you can run `which cmake` to see what cmake you are\n",
      "          actually using.  If it tells you it's some cmake from any kind of python\n",
      "          packager delete it and install an official cmake.\n",
      "      \n",
      "          More generally, cmake is not installed if when you open a terminal window\n",
      "          and type\n",
      "             cmake --version\n",
      "          you get an error.  So you can use that as a very basic test to see if you\n",
      "          have cmake installed.  That is, if cmake --version doesn't run from the\n",
      "          same terminal window from which you are reading this error message, then\n",
      "          you have not installed cmake.  Windows users should take note that they\n",
      "          need to tell the cmake installer to add cmake to their PATH.  Since you\n",
      "          can't run commands that are not in your PATH.  This is how the PATH works\n",
      "          on Linux as well, but failing to add cmake to the PATH is a particularly\n",
      "          common problem on windows and rarely a problem on Linux.\n",
      "      \n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for dlib\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "   Running setup.py install for dlib did not run successfully.\n",
      "   exit code: 1\n",
      "  > [41 lines of output]\n",
      "      running install\n",
      "      running build\n",
      "      running build_ext\n",
      "      \n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      \n",
      "                         CMake is not installed on your system!\n",
      "      \n",
      "          Or it is possible some broken copy of cmake is installed on your system.\n",
      "          It is unfortunately very common for python package managers to include\n",
      "          broken copies of cmake.  So if the error above this refers to some file\n",
      "          path to a cmake file inside a python or anaconda or miniconda path then you\n",
      "          should delete that broken copy of cmake from your computer.\n",
      "      \n",
      "          Instead, please get an official copy of cmake from one of these known good\n",
      "          sources of an official cmake:\n",
      "              - cmake.org (this is how windows users should get cmake)\n",
      "              - apt install cmake (for Ubuntu or Debian based systems)\n",
      "              - yum install cmake (for Redhat or CenOS based systems)\n",
      "      \n",
      "          On a linux machine you can run `which cmake` to see what cmake you are\n",
      "          actually using.  If it tells you it's some cmake from any kind of python\n",
      "          packager delete it and install an official cmake.\n",
      "      \n",
      "          More generally, cmake is not installed if when you open a terminal window\n",
      "          and type\n",
      "             cmake --version\n",
      "          you get an error.  So you can use that as a very basic test to see if you\n",
      "          have cmake installed.  That is, if cmake --version doesn't run from the\n",
      "          same terminal window from which you are reading this error message, then\n",
      "          you have not installed cmake.  Windows users should take note that they\n",
      "          need to tell the cmake installer to add cmake to their PATH.  Since you\n",
      "          can't run commands that are not in your PATH.  This is how the PATH works\n",
      "          on Linux as well, but failing to add cmake to the PATH is a particularly\n",
      "          common problem on windows and rarely a problem on Linux.\n",
      "      \n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      " Encountered error while trying to install package.\n",
      "> dlib\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install requests ultralytics Pillow pytorch\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.5.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: sentence-transformers, torchvision\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1uQeR0jUZRP_4XUg9UbNhW1xx1mH-qkWg",
     "timestamp": 1717395459592
    },
    {
     "file_id": "1hmpdjZqDISgAMSwJzQDw-Jnkd0p-kTBa",
     "timestamp": 1717392966099
    },
    {
     "file_id": "1Ek41jF2Zo52jQFUJWwau3Cih6YMP-kmY",
     "timestamp": 1717348967197
    },
    {
     "file_id": "1TvAif6jTpS48FVcC2zZ5CkWQpc3mv9x-",
     "timestamp": 1717335972981
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
</file>

<file path="training_code/requirements.txt">
fastapi==0.108.0
uvicorn[standard]
ultralytics
numpy
keras
opencv-python
requests
boto3
dnspython
python-decouple
face-recognition
python-multipart
roboflow
inference-sdk
tensorflow


# tensorflow[and-cuda]
</file>

</files>
