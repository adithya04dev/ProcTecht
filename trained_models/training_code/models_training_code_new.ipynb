{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 83039,
     "status": "ok",
     "timestamp": 1717393178669,
     "user": {
      "displayName": "afith 234",
      "userId": "04481233657332223077"
     },
     "user_tz": -330
    },
    "id": "xSOpctm7twwa",
    "outputId": "d9093eeb-ad79-489c-a2ad-2030a242edd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h/content\n",
      "/content/datasets\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet ultralytics\n",
    "!pip install --quiet roboflow\n",
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)\n",
    "!mkdir {HOME}/datasets\n",
    "%cd {HOME}/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 456,
     "status": "error",
     "timestamp": 1717335506247,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "16670161079480334602"
     },
     "user_tz": -330
    },
    "id": "TEJIuaJJchlF",
    "outputId": "cc1c3fc7-a75d-4ef8-ec86-4160b7899e91"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-fa198b04c639>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-fa198b04c639>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    accident detection model\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#accident detection model\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"0cCp3vcWRdYFCnoJzWu7\")\n",
    "project = rf.workspace(\"abc-llt0y\").project(\"accidetect-a9uvo\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1647002,
     "status": "ok",
     "timestamp": 1717331978544,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "16670161079480334602"
     },
     "user_tz": -330
    },
    "id": "h5GUkZRbOxHu",
    "outputId": "7fdd620a-4223-4ecc-fe3e-b8ee8c463074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n",
      "100% 21.5M/21.5M [00:00<00:00, 188MB/s]\n",
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/AcciDetect-3/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100% 755k/755k [00:00<00:00, 26.9MB/s]\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11139470 parameters, 11139454 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100% 6.23M/6.23M [00:00<00:00, 121MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/AcciDetect-3/train/labels... 5849 images, 0 backgrounds, 0 corrupt: 100% 5849/5849 [00:02<00:00, 1973.91it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/AcciDetect-3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/AcciDetect-3/valid/labels... 712 images, 0 backgrounds, 0 corrupt: 100% 712/712 [00:00<00:00, 1260.40it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/AcciDetect-3/valid/labels.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 512 train, 512 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10       2.7G      1.118      1.585      1.095         55        512: 100% 366/366 [02:34<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  96% 22/23 [00:11<00:00,  1.51it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:12<00:00,  1.83it/s]\n",
      "                   all        712       3335      0.797      0.438      0.555      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      2.65G     0.9806     0.9133      1.026         35        512: 100% 366/366 [02:25<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:09<00:00,  2.39it/s]\n",
      "                   all        712       3335      0.603       0.52      0.528      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      2.61G     0.9547     0.8525      1.019         33        512: 100% 366/366 [02:23<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:09<00:00,  2.49it/s]\n",
      "                   all        712       3335      0.675      0.563      0.599      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      2.64G     0.9104      0.752          1         40        512: 100% 366/366 [02:25<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:09<00:00,  2.36it/s]\n",
      "                   all        712       3335      0.764      0.604      0.658      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      2.64G     0.8586     0.6735     0.9796         58        512: 100% 366/366 [02:23<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:12<00:00,  1.82it/s]\n",
      "                   all        712       3335      0.741      0.727      0.764      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      2.63G      0.826     0.6167     0.9657         35        512: 100% 366/366 [02:22<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:13<00:00,  1.75it/s]\n",
      "                   all        712       3335      0.835      0.717       0.79      0.637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      2.64G     0.7862     0.5595     0.9482         38        512: 100% 366/366 [02:22<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:13<00:00,  1.72it/s]\n",
      "                   all        712       3335      0.747      0.812      0.863      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      2.65G     0.7555     0.5046     0.9347         29        512: 100% 366/366 [02:23<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:13<00:00,  1.77it/s]\n",
      "                   all        712       3335      0.759      0.885      0.912      0.761\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      2.63G     0.7297     0.4717     0.9256         41        512: 100% 366/366 [02:22<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:13<00:00,  1.70it/s]\n",
      "                   all        712       3335      0.908      0.796      0.912      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      2.64G     0.6996     0.4391     0.9153         54        512: 100% 366/366 [02:22<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:11<00:00,  2.01it/s]\n",
      "                   all        712       3335      0.794      0.864      0.925      0.796\n",
      "\n",
      "10 epochs completed in 0.441 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11129454 parameters, 0 gradients, 28.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 23/23 [00:14<00:00,  1.58it/s]\n",
      "                   all        712       3335      0.793      0.864      0.925      0.795\n",
      "                  bike        177        448        0.9      0.944      0.967      0.801\n",
      "    bike_bike_accident         34         34      0.818      0.853      0.949      0.794\n",
      "  bike_person_accident         15         15      0.777          1      0.995      0.884\n",
      "                   car        546       1996      0.925      0.973      0.982      0.833\n",
      "     car_bike_accident         31         31      0.641      0.903      0.942      0.837\n",
      "      car_car_accident        313        322      0.923      0.978      0.987      0.905\n",
      "   car_object_accident         33         33      0.788      0.939       0.93      0.844\n",
      "   car_person_accident          5          5      0.529      0.234      0.614      0.567\n",
      "                person        185        451      0.834      0.949      0.961      0.691\n",
      "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=10 imgsz=512 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 14433,
     "status": "ok",
     "timestamp": 1717341201205,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "clpBvaUat63X",
    "outputId": "59bbf352-8460-472a-a740-63537eb3d027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Real-Time-Accident-Detection-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 270015/270015 [00:09<00:00, 28409.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Real-Time-Accident-Detection-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14767/14767 [00:02<00:00, 6149.34it/s]\n"
     ]
    }
   ],
   "source": [
    "#model that has api present\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"puyush-fipgg\").project(\"real-time-accident-detection\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 462569,
     "status": "ok",
     "timestamp": 1717343159029,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "BtLtEv5XyOCK",
    "outputId": "c92dbe31-6175-4008-b045-9e1e9afc7366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/Real-Time-Accident-Detection-1/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11139470 parameters, 11139454 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/Real-Time-Accident-Detection-1/train/labels.cache... 7125 images, 0 backgrounds, 0 corrupt: 100% 7125/7125 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Real-Time-Accident-Detection-1/valid/labels.cache... 254 images, 0 backgrounds, 0 corrupt: 100% 254/254 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.23G      1.063      1.635      1.106         23        640: 100% 446/446 [02:51<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:03<00:00,  2.62it/s]\n",
      "                   all        254       1807      0.599      0.316      0.348      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10       4.2G     0.9277     0.8657      1.041         26        640: 100% 446/446 [02:43<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:04<00:00,  1.91it/s]\n",
      "                   all        254       1807      0.526       0.33      0.341      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      4.21G     0.8963      0.801      1.032          9        640: 100% 446/446 [02:43<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:05<00:00,  1.49it/s]\n",
      "                   all        254       1807      0.652      0.344      0.371      0.194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      4.19G     0.8515     0.7139      1.007         21        640: 100% 446/446 [02:43<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:05<00:00,  1.57it/s]\n",
      "                   all        254       1807      0.677       0.42      0.446      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      4.18G     0.8085     0.6342     0.9887         13        640: 100% 446/446 [02:43<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:03<00:00,  2.31it/s]\n",
      "                   all        254       1807      0.598      0.488       0.46      0.252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      4.19G     0.7687     0.5732     0.9684         10        640: 100% 446/446 [02:45<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:02<00:00,  2.72it/s]\n",
      "                   all        254       1807      0.566      0.508      0.476       0.25\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      4.17G     0.7292     0.5223     0.9546         12        640: 100% 446/446 [02:45<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:02<00:00,  2.72it/s]\n",
      "                   all        254       1807      0.637      0.542      0.539      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10       4.2G     0.6969     0.4727     0.9387         13        640: 100% 446/446 [02:43<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:02<00:00,  2.69it/s]\n",
      "                   all        254       1807      0.634      0.553      0.561      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      4.19G     0.6716     0.4359     0.9277         14        640: 100% 446/446 [02:44<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:04<00:00,  1.88it/s]\n",
      "                   all        254       1807      0.772      0.524      0.601      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      4.23G     0.6455     0.4051     0.9182         15        640: 100% 446/446 [02:40<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:05<00:00,  1.47it/s]\n",
      "                   all        254       1807      0.737      0.554      0.594      0.337\n",
      "\n",
      "10 epochs completed in 0.473 hours.\n",
      "Optimizer stripped from runs/detect/train3/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train3/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train3/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11129454 parameters, 0 gradients, 28.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:12<00:00,  1.57s/it]\n",
      "                   all        254       1807      0.771      0.524      0.601      0.345\n",
      "                  bike        106        374       0.91      0.624      0.809      0.376\n",
      "    bike_bike_accident         14         14      0.625      0.643      0.549      0.342\n",
      "  bike_object_accident          2          2          1          0     0.0108    0.00325\n",
      "  bike_person_accident          9          9      0.451      0.667       0.62      0.285\n",
      "                   car        205        836      0.909      0.616      0.789      0.474\n",
      "     car_bike_accident         28         28      0.781      0.536      0.664      0.418\n",
      "      car_car_accident         94         94      0.776      0.883      0.793      0.564\n",
      "   car_object_accident         12         12      0.467       0.25      0.362      0.237\n",
      "   car_person_accident          4          4      0.913       0.75       0.87      0.524\n",
      "                person        111        434      0.882      0.275      0.546      0.226\n",
      "Speed: 0.6ms preprocess, 5.9ms inference, 0.0ms loss, 6.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19184,
     "status": "ok",
     "timestamp": 1717394572602,
     "user": {
      "displayName": "afith 234",
      "userId": "04481233657332223077"
     },
     "user_tz": -330
    },
    "id": "7DZsBRdlysoJ",
    "outputId": "21b0c472-b387-47d4-ca94-c66544e6b01b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWpDcEok95t0"
   },
   "outputs": [],
   "source": [
    "##weapons dection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 16160,
     "status": "ok",
     "timestamp": 1717336226287,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "HFH0l64pKvDY",
    "outputId": "0a4dc41d-5965-4c2f-9f13-5374e7dc1d7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in guns_n_knives-3 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 275489/275489 [00:04<00:00, 63920.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to guns_n_knives-3 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19682/19682 [00:05<00:00, 3678.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"crime-detection\").project(\"guns_n_knives-h4bky\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1899798,
     "status": "ok",
     "timestamp": 1717338175319,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "aepKMttyK64e",
    "outputId": "20f50daf-f234-4230-ee61-88200f791294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n",
      "100% 21.5M/21.5M [00:00<00:00, 181MB/s]\n",
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/guns_n_knives-3/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100% 755k/755k [00:00<00:00, 22.4MB/s]\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11136374 parameters, 11136358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100% 6.23M/6.23M [00:00<00:00, 117MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/guns_n_knives-3/train/labels... 6885 images, 0 backgrounds, 0 corrupt: 100% 6885/6885 [00:03<00:00, 1853.43it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/guns_n_knives-3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/guns_n_knives-3/valid/labels... 1969 images, 0 backgrounds, 0 corrupt: 100% 1969/1969 [00:01<00:00, 1083.15it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/guns_n_knives-3/valid/labels.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.25G      2.002      2.828      1.931         13        640: 100% 431/431 [02:43<00:00,  2.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:25<00:00,  2.39it/s]\n",
      "                   all       1969       2818      0.298      0.248      0.196     0.0792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      4.22G      2.129      2.527      2.077          6        640: 100% 431/431 [02:35<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:25<00:00,  2.43it/s]\n",
      "                   all       1969       2818      0.383      0.312       0.28       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      4.15G      2.056      2.356      2.037          8        640: 100% 431/431 [02:33<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:23<00:00,  2.60it/s]\n",
      "                   all       1969       2818      0.381      0.317      0.265      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      4.18G      1.932      2.125      1.923          6        640: 100% 431/431 [02:34<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:24<00:00,  2.50it/s]\n",
      "                   all       1969       2818      0.517      0.401      0.402      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      4.15G      1.834      1.906      1.833          8        640: 100% 431/431 [02:39<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:24<00:00,  2.49it/s]\n",
      "                   all       1969       2818      0.599      0.485      0.515      0.253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      4.18G      1.751      1.743      1.758          5        640: 100% 431/431 [02:38<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:26<00:00,  2.31it/s]\n",
      "                   all       1969       2818      0.691      0.574      0.613      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10       4.3G      1.673      1.575      1.696          5        640: 100% 431/431 [02:38<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:24<00:00,  2.52it/s]\n",
      "                   all       1969       2818      0.747      0.602      0.652       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      4.17G      1.605      1.445      1.638          8        640: 100% 431/431 [02:35<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:24<00:00,  2.49it/s]\n",
      "                   all       1969       2818      0.766      0.616      0.662      0.371\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      4.15G      1.538      1.325      1.581          6        640: 100% 431/431 [02:32<00:00,  2.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:25<00:00,  2.44it/s]\n",
      "                   all       1969       2818      0.814      0.656      0.714      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      4.19G       1.48      1.221      1.532         10        640: 100% 431/431 [02:32<00:00,  2.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:22<00:00,  2.71it/s]\n",
      "                   all       1969       2818      0.821      0.689      0.733      0.426\n",
      "\n",
      "10 epochs completed in 0.510 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:30<00:00,  2.03it/s]\n",
      "                   all       1969       2818       0.82      0.689      0.733      0.426\n",
      "                   gun        970       1559      0.766      0.526      0.562      0.316\n",
      "                 knife        999       1259      0.874      0.852      0.905      0.536\n",
      "Speed: 0.3ms preprocess, 4.7ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10073,
     "status": "ok",
     "timestamp": 1717339700014,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "yykMrdz4LjrV",
    "outputId": "b1e653c5-ce00-41e3-a0f2-5cccfc9151ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Crack-Detection-2 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213409/213409 [00:05<00:00, 36490.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Crack-Detection-2 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10022/10022 [00:01<00:00, 5979.49it/s]\n"
     ]
    }
   ],
   "source": [
    "#cracks and dents detection\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"ta-8behn\").project(\"crack-detection-ypnwo\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1091134,
     "status": "ok",
     "timestamp": 1717340920809,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "6QqHBRALbA5m",
    "outputId": "eeeec1f2-d850-416c-c5a0-703af47235c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/Crack-Detection-2/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/Crack-Detection-2/train/labels... 4122 images, 0 backgrounds, 0 corrupt: 100% 4122/4122 [00:01<00:00, 2159.03it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/Crack-Detection-2/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/Crack-Detection-2/valid/labels... 589 images, 0 backgrounds, 0 corrupt: 100% 589/589 [00:00<00:00, 690.64it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/Crack-Detection-2/valid/labels.cache\n",
      "Plotting labels to runs/detect/train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.23G      1.424      2.092      1.874         10        640: 100% 258/258 [01:39<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:08<00:00,  2.36it/s]\n",
      "                   all        589        629      0.585      0.666       0.61      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      4.18G      1.386      1.352      1.833         10        640: 100% 258/258 [01:35<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:08<00:00,  2.28it/s]\n",
      "                   all        589        629       0.61      0.474      0.552      0.277\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      4.13G        1.3      1.225      1.742         10        640: 100% 258/258 [01:35<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:06<00:00,  2.77it/s]\n",
      "                   all        589        629      0.848      0.684      0.825      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      4.17G       1.19      1.086       1.66         10        640: 100% 258/258 [01:33<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:10<00:00,  1.82it/s]\n",
      "                   all        589        629      0.849      0.831      0.889      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      4.15G      1.115     0.9727       1.58         11        640: 100% 258/258 [01:35<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.44it/s]\n",
      "                   all        589        629      0.868      0.812      0.904      0.565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      4.17G      1.063     0.9007      1.526         10        640: 100% 258/258 [01:33<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.60it/s]\n",
      "                   all        589        629      0.825      0.878      0.916       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      4.15G     0.9871     0.7961      1.466         11        640: 100% 258/258 [01:34<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:10<00:00,  1.82it/s]\n",
      "                   all        589        629      0.934      0.851      0.939       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      4.17G     0.9397     0.7219      1.418         10        640: 100% 258/258 [01:33<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.63it/s]\n",
      "                   all        589        629      0.943      0.894      0.957      0.696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      4.14G     0.9119     0.6643      1.392         10        640: 100% 258/258 [01:35<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:07<00:00,  2.57it/s]\n",
      "                   all        589        629      0.933      0.912      0.965      0.719\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      4.17G     0.8432     0.6097      1.338         12        640: 100% 258/258 [01:33<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:09<00:00,  1.97it/s]\n",
      "                   all        589        629      0.936      0.914      0.966      0.743\n",
      "\n",
      "10 epochs completed in 0.292 hours.\n",
      "Optimizer stripped from runs/detect/train2/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train2/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train2/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 19/19 [00:11<00:00,  1.72it/s]\n",
      "                   all        589        629      0.936      0.914      0.965      0.743\n",
      "Speed: 0.3ms preprocess, 4.8ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlAmJ-JTbi_n"
   },
   "outputs": [],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=10 imgsz=640 plots=True project=/content/datasets/runs name=cracks\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHnjGJfZpllt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MAM2f06plo7"
   },
   "outputs": [],
   "source": [
    "#fights detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4093,
     "status": "ok",
     "timestamp": 1717344098760,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "4npwQkn_plsD",
    "outputId": "e02fc64e-cd44-4de2-fd74-9107067d3376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in gisc-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35074/35074 [00:01<00:00, 33238.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to gisc-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1616/1616 [00:00<00:00, 6909.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"mslee\").project(\"gisc\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1812608,
     "status": "ok",
     "timestamp": 1717346328652,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "M7mRRemopous",
    "outputId": "d0618803-edb8-45b2-a828-f281fa4e297e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/gisc-1/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train8\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train8', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/gisc-1/train/labels.cache... 636 images, 0 backgrounds, 0 corrupt: 100% 636/636 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/gisc-1/valid/labels.cache... 81 images, 0 backgrounds, 0 corrupt: 100% 81/81 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train8/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train8\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100       4.2G      1.583      3.222      1.712         26        640: 100% 40/40 [00:19<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.33it/s]\n",
      "                   all         81         92      0.105      0.272     0.0716     0.0265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100      4.27G      1.818      2.329      1.864         23        640: 100% 40/40 [00:16<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.82it/s]\n",
      "                   all         81         92     0.0498      0.435     0.0368     0.0119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100      4.14G      1.926      2.407      1.978         24        640: 100% 40/40 [00:16<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.62it/s]\n",
      "                   all         81         92    0.00409      0.685     0.0037    0.00124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100      4.14G      1.987      2.513       2.04         28        640: 100% 40/40 [00:16<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.61it/s]\n",
      "                   all         81         92     0.0907      0.326     0.0735     0.0225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      4.15G      1.914      2.384       1.97         38        640: 100% 40/40 [00:14<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.27it/s]\n",
      "                   all         81         92     0.0473      0.109     0.0384     0.0118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100      4.14G      1.941      2.376      2.005         27        640: 100% 40/40 [00:13<00:00,  3.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.67it/s]\n",
      "                   all         81         92    0.00416      0.261    0.00361     0.0012\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100      4.14G      1.841      2.338      1.954         27        640: 100% 40/40 [00:13<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.68it/s]\n",
      "                   all         81         92      0.212      0.231      0.155     0.0615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      4.14G      1.821      2.264      1.951         21        640: 100% 40/40 [00:14<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.76it/s]\n",
      "                   all         81         92      0.161      0.207       0.11     0.0388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100      4.14G      1.767      2.194      1.905         31        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.68it/s]\n",
      "                   all         81         92      0.214      0.261      0.123     0.0364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100      4.15G       1.77      2.224      1.902         26        640: 100% 40/40 [00:16<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.66it/s]\n",
      "                   all         81         92      0.226      0.304      0.197     0.0725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100      4.15G      1.779      2.213      1.892         21        640: 100% 40/40 [00:15<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.80it/s]\n",
      "                   all         81         92        0.3      0.312      0.222     0.0841\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100      4.14G      1.717      2.151      1.834         35        640: 100% 40/40 [00:14<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.53it/s]\n",
      "                   all         81         92      0.209      0.315      0.188     0.0766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100      4.14G      1.716      2.126      1.836         19        640: 100% 40/40 [00:12<00:00,  3.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.42it/s]\n",
      "                   all         81         92      0.365      0.288      0.219     0.0846\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100      4.14G      1.693      2.074      1.829         31        640: 100% 40/40 [00:13<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.10it/s]\n",
      "                   all         81         92      0.281        0.5      0.285      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100      4.14G      1.614       1.97       1.73         20        640: 100% 40/40 [00:14<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.56it/s]\n",
      "                   all         81         92      0.348      0.272      0.251     0.0997\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100      4.13G      1.664      1.987      1.778         32        640: 100% 40/40 [00:16<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.90it/s]\n",
      "                   all         81         92      0.299      0.424        0.3      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100      4.14G       1.62      1.942      1.754         34        640: 100% 40/40 [00:16<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.32it/s]\n",
      "                   all         81         92      0.148      0.381      0.122     0.0491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100      4.14G      1.598      1.908      1.731         25        640: 100% 40/40 [00:16<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.84it/s]\n",
      "                   all         81         92      0.326      0.348      0.277      0.107\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100      4.14G      1.608      1.917      1.753         21        640: 100% 40/40 [00:14<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.51it/s]\n",
      "                   all         81         92      0.264       0.37      0.254     0.0948\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100      4.13G      1.555      1.862      1.705         31        640: 100% 40/40 [00:12<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.61it/s]\n",
      "                   all         81         92      0.361      0.467      0.331       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100      4.14G      1.518      1.755      1.677         30        640: 100% 40/40 [00:13<00:00,  2.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.68it/s]\n",
      "                   all         81         92      0.373      0.356      0.289      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100      4.14G      1.573      1.819      1.684         32        640: 100% 40/40 [00:15<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.47it/s]\n",
      "                   all         81         92      0.433      0.315      0.338      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100      4.14G      1.563      1.875      1.685         26        640: 100% 40/40 [00:15<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.46it/s]\n",
      "                   all         81         92      0.321        0.5      0.323      0.146\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100      4.14G      1.486      1.786      1.654         29        640: 100% 40/40 [00:15<00:00,  2.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.51it/s]\n",
      "                   all         81         92      0.418       0.38      0.394      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100      4.14G      1.512      1.725      1.644         30        640: 100% 40/40 [00:15<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
      "                   all         81         92      0.403      0.446      0.395      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100      4.14G      1.486      1.697      1.613         21        640: 100% 40/40 [00:14<00:00,  2.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.41it/s]\n",
      "                   all         81         92      0.412      0.467      0.457      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100      4.14G      1.516      1.747      1.659         30        640: 100% 40/40 [00:12<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.56it/s]\n",
      "                   all         81         92      0.288       0.44      0.301      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100      4.13G      1.467      1.721      1.616         27        640: 100% 40/40 [00:14<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.52it/s]\n",
      "                   all         81         92      0.422      0.478      0.453       0.23\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100      4.14G      1.408      1.624      1.611         23        640: 100% 40/40 [00:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.73it/s]\n",
      "                   all         81         92      0.423      0.457      0.442      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100      4.15G      1.485      1.699      1.633         29        640: 100% 40/40 [00:15<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.58it/s]\n",
      "                   all         81         92      0.588      0.435      0.465      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100      4.14G      1.427       1.66      1.603         21        640: 100% 40/40 [00:16<00:00,  2.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.47it/s]\n",
      "                   all         81         92      0.491      0.391      0.465      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100      4.15G      1.445      1.675      1.598         22        640: 100% 40/40 [00:16<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.16it/s]\n",
      "                   all         81         92      0.491      0.457      0.467      0.249\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100      4.13G      1.418      1.648      1.597         27        640: 100% 40/40 [00:14<00:00,  2.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.38it/s]\n",
      "                   all         81         92      0.498      0.446       0.47      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100      4.14G      1.394      1.567      1.567         29        640: 100% 40/40 [00:13<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.51it/s]\n",
      "                   all         81         92       0.56      0.522      0.518      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100      4.14G      1.392       1.55      1.571         26        640: 100% 40/40 [00:13<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.83it/s]\n",
      "                   all         81         92      0.603      0.446      0.492      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100      4.16G      1.397      1.569      1.575         22        640: 100% 40/40 [00:14<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.57it/s]\n",
      "                   all         81         92      0.494        0.5      0.439      0.238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100      4.15G      1.332      1.553      1.547         24        640: 100% 40/40 [00:16<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.67it/s]\n",
      "                   all         81         92       0.48       0.62      0.555      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100      4.14G      1.353      1.497      1.554         28        640: 100% 40/40 [00:16<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.54it/s]\n",
      "                   all         81         92      0.473      0.526      0.457      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100      4.14G      1.335      1.506      1.537         25        640: 100% 40/40 [00:16<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.53it/s]\n",
      "                   all         81         92      0.608      0.446      0.499      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100      4.14G       1.33      1.464      1.499         32        640: 100% 40/40 [00:14<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.38it/s]\n",
      "                   all         81         92       0.55      0.531      0.528      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100      4.14G      1.316      1.468      1.506         17        640: 100% 40/40 [00:13<00:00,  3.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.60it/s]\n",
      "                   all         81         92      0.618      0.522      0.533      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100      4.15G      1.334      1.458      1.517         31        640: 100% 40/40 [00:13<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.76it/s]\n",
      "                   all         81         92      0.649      0.467      0.563      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100      4.15G      1.295       1.49      1.502         27        640: 100% 40/40 [00:13<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.29it/s]\n",
      "                   all         81         92      0.655      0.522      0.562      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100      4.14G       1.31      1.467      1.497         19        640: 100% 40/40 [00:15<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.81it/s]\n",
      "                   all         81         92      0.564      0.562      0.551      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100      4.14G      1.308      1.361        1.5         26        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.64it/s]\n",
      "                   all         81         92      0.578      0.489      0.532      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100      4.15G      1.248      1.343      1.459         28        640: 100% 40/40 [00:16<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.70it/s]\n",
      "                   all         81         92      0.507      0.478      0.457      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100      4.14G      1.305       1.37      1.484         33        640: 100% 40/40 [00:16<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.33it/s]\n",
      "                   all         81         92      0.573       0.57      0.555      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/100      4.13G      1.269      1.349      1.458         34        640: 100% 40/40 [00:13<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.41it/s]\n",
      "                   all         81         92      0.444      0.587      0.487      0.247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100      4.14G      1.246      1.318      1.451         21        640: 100% 40/40 [00:12<00:00,  3.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.68it/s]\n",
      "                   all         81         92       0.59      0.484      0.536      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100      4.14G      1.254      1.319      1.455         30        640: 100% 40/40 [00:14<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.33it/s]\n",
      "                   all         81         92      0.583      0.489      0.556      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100      4.14G      1.209      1.272      1.415         22        640: 100% 40/40 [00:15<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.60it/s]\n",
      "                   all         81         92      0.531      0.565      0.542      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/100      4.14G      1.226      1.271      1.428         21        640: 100% 40/40 [00:16<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.60it/s]\n",
      "                   all         81         92       0.57      0.609      0.571      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/100      4.14G      1.191      1.232      1.408         18        640: 100% 40/40 [00:16<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.57it/s]\n",
      "                   all         81         92      0.555        0.5      0.533      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/100      4.15G      1.217      1.222      1.427         23        640: 100% 40/40 [00:15<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.94it/s]\n",
      "                   all         81         92       0.69        0.5      0.608      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/100      4.14G      1.193      1.218      1.417         30        640: 100% 40/40 [00:13<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.26it/s]\n",
      "                   all         81         92      0.516      0.565      0.552      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/100      4.15G      1.144      1.191      1.384         24        640: 100% 40/40 [00:13<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.86it/s]\n",
      "                   all         81         92      0.614      0.572      0.614      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/100      4.14G      1.195      1.233       1.41         36        640: 100% 40/40 [00:14<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.93it/s]\n",
      "                   all         81         92       0.61       0.62      0.653      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/100      4.14G      1.166      1.163      1.399         20        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.44it/s]\n",
      "                   all         81         92       0.63      0.556      0.604      0.334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/100      4.14G       1.13      1.161      1.349         26        640: 100% 40/40 [00:15<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.52it/s]\n",
      "                   all         81         92      0.712      0.543        0.6      0.331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/100      4.14G      1.108      1.132      1.362         30        640: 100% 40/40 [00:16<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.73it/s]\n",
      "                   all         81         92      0.536      0.511       0.56      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/100      4.15G       1.13      1.156      1.378         21        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.15it/s]\n",
      "                   all         81         92      0.597      0.641      0.619      0.347\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/100      4.14G       1.14      1.118      1.383         34        640: 100% 40/40 [00:13<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.33it/s]\n",
      "                   all         81         92      0.611      0.565      0.575      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/100      4.14G      1.149      1.125      1.378         25        640: 100% 40/40 [00:13<00:00,  3.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.77it/s]\n",
      "                   all         81         92      0.582      0.554      0.557      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/100      4.14G      1.079      1.087      1.346         34        640: 100% 40/40 [00:13<00:00,  2.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.09it/s]\n",
      "                   all         81         92      0.591      0.554       0.59      0.326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/100      4.15G      1.137      1.097      1.382         24        640: 100% 40/40 [00:15<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.76it/s]\n",
      "                   all         81         92      0.569      0.576      0.564      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/100      4.14G      1.075      1.103      1.347         27        640: 100% 40/40 [00:16<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.73it/s]\n",
      "                   all         81         92      0.469      0.644      0.596      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/100      4.14G      1.043      1.016      1.315         32        640: 100% 40/40 [00:16<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.88it/s]\n",
      "                   all         81         92      0.705      0.522      0.578      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/100      4.14G      1.074      1.036      1.325         32        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.83it/s]\n",
      "                   all         81         92      0.555      0.587      0.565      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/100      4.14G      1.051      1.003      1.315         25        640: 100% 40/40 [00:15<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.29it/s]\n",
      "                   all         81         92      0.568      0.663      0.632      0.327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/100      4.14G      1.051      1.021      1.302         19        640: 100% 40/40 [00:13<00:00,  2.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.54it/s]\n",
      "                   all         81         92      0.554       0.58      0.525      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/100      4.14G      1.053     0.9957        1.3         26        640: 100% 40/40 [00:12<00:00,  3.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.46it/s]\n",
      "                   all         81         92      0.589      0.686      0.677      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/100      4.14G       1.05     0.9808      1.314         23        640: 100% 40/40 [00:14<00:00,  2.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.21it/s]\n",
      "                   all         81         92      0.622      0.555       0.61      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/100      4.14G      1.019     0.9603      1.277         26        640: 100% 40/40 [00:16<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.77it/s]\n",
      "                   all         81         92      0.566       0.63      0.598      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/100      4.14G      1.001     0.9261      1.262         34        640: 100% 40/40 [00:16<00:00,  2.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.71it/s]\n",
      "                   all         81         92       0.65        0.5      0.586      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/100      4.14G      1.029     0.9578      1.282         24        640: 100% 40/40 [00:16<00:00,  2.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.73it/s]\n",
      "                   all         81         92       0.71      0.532      0.627      0.371\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/100      4.14G       1.01     0.9588      1.282         26        640: 100% 40/40 [00:15<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.52it/s]\n",
      "                   all         81         92      0.657      0.562      0.591      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/100      4.14G      1.008      0.941       1.28         25        640: 100% 40/40 [00:14<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.36it/s]\n",
      "                   all         81         92      0.666      0.565      0.642       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/100      4.14G     0.9537     0.9233      1.254         28        640: 100% 40/40 [00:13<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.61it/s]\n",
      "                   all         81         92      0.735      0.576      0.655      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/100      4.15G      0.974     0.9089       1.26         27        640: 100% 40/40 [00:14<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.66it/s]\n",
      "                   all         81         92      0.654      0.595      0.631      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/100      4.14G     0.9721     0.8829      1.245         37        640: 100% 40/40 [00:15<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.43it/s]\n",
      "                   all         81         92      0.682      0.583       0.63      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/100      4.14G     0.9292     0.8627      1.245         32        640: 100% 40/40 [00:16<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.74it/s]\n",
      "                   all         81         92      0.681      0.587       0.66      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/100      4.14G     0.9242     0.8581      1.228         30        640: 100% 40/40 [00:16<00:00,  2.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.47it/s]\n",
      "                   all         81         92      0.759      0.617      0.674      0.356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/100      4.14G      0.927     0.8606      1.226         30        640: 100% 40/40 [00:16<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.06it/s]\n",
      "                   all         81         92      0.648       0.62       0.68      0.375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/100      4.14G     0.9392     0.8729      1.247         26        640: 100% 40/40 [00:14<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.62it/s]\n",
      "                   all         81         92      0.741      0.598      0.675      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/100      4.14G      0.911     0.8414      1.222         22        640: 100% 40/40 [00:13<00:00,  3.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.69it/s]\n",
      "                   all         81         92      0.774      0.576      0.665      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/100      4.15G       0.91       0.85      1.209         23        640: 100% 40/40 [00:13<00:00,  2.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.63it/s]\n",
      "                   all         81         92      0.615       0.63      0.681       0.37\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/100      4.13G      0.913     0.8317      1.212         23        640: 100% 40/40 [00:15<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.56it/s]\n",
      "                   all         81         92      0.701      0.598      0.653      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/100      4.14G     0.8821     0.7977      1.193         25        640: 100% 40/40 [00:15<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.67it/s]\n",
      "                   all         81         92      0.724      0.565      0.674      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/100      4.14G     0.8873     0.8134       1.21         23        640: 100% 40/40 [00:16<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.64it/s]\n",
      "                   all         81         92      0.792      0.538      0.682      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/100      4.14G     0.8853     0.8256      1.211         26        640: 100% 40/40 [00:17<00:00,  2.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.58it/s]\n",
      "                   all         81         92      0.726      0.576      0.666      0.397\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/100      4.14G     0.7617     0.6852       1.13         13        640: 100% 40/40 [00:17<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.80it/s]\n",
      "                   all         81         92      0.784      0.598      0.677      0.389\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/100      4.14G     0.7707     0.6332      1.133         12        640: 100% 40/40 [00:14<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.43it/s]\n",
      "                   all         81         92      0.781      0.587      0.687      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/100      4.14G     0.7287     0.6024      1.123         13        640: 100% 40/40 [00:12<00:00,  3.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.77it/s]\n",
      "                   all         81         92      0.737      0.609      0.725      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/100      4.14G      0.719     0.5787      1.117         13        640: 100% 40/40 [00:13<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.92it/s]\n",
      "                   all         81         92      0.694      0.652      0.702      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/100      4.14G      0.714     0.5726       1.11         13        640: 100% 40/40 [00:15<00:00,  2.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.87it/s]\n",
      "                   all         81         92      0.727       0.63      0.693      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/100      4.14G     0.7165      0.557      1.103         14        640: 100% 40/40 [00:16<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.81it/s]\n",
      "                   all         81         92      0.763      0.561      0.671      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/100      4.14G     0.7077     0.5391      1.082         13        640: 100% 40/40 [00:15<00:00,  2.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.25it/s]\n",
      "                   all         81         92      0.764      0.563       0.68      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/100      4.14G     0.6952     0.5508      1.091         16        640: 100% 40/40 [00:13<00:00,  3.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.51it/s]\n",
      "                   all         81         92       0.76      0.586      0.686      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/100      4.14G     0.6914     0.5481      1.095         12        640: 100% 40/40 [00:12<00:00,  3.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.79it/s]\n",
      "                   all         81         92      0.696       0.62      0.684      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/100      4.14G     0.6761     0.5256      1.079         15        640: 100% 40/40 [00:15<00:00,  2.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:00<00:00,  3.01it/s]\n",
      "                   all         81         92       0.76      0.609      0.683      0.383\n",
      "\n",
      "100 epochs completed in 0.495 hours.\n",
      "Optimizer stripped from runs/detect/train8/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train8/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train8/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.45it/s]\n",
      "                   all         81         92      0.693      0.652      0.702      0.402\n",
      "Speed: 0.3ms preprocess, 4.7ms inference, 0.0ms loss, 5.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train8\u001b[0m\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=100 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJMsBbPgqY6Q"
   },
   "outputs": [],
   "source": [
    "## fire and smoke detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3ainjsK4m2B"
   },
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"my-space-3zzwr\").project(\"fire-smoke-detection-odvk6\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjpdVlIe4sCn"
   },
   "outputs": [],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=4 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40rmve4_4slM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1xSYuAS4tLh"
   },
   "outputs": [],
   "source": [
    "## climber detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4105,
     "status": "ok",
     "timestamp": 1717347547540,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "QGGm9xNC4wyX",
    "outputId": "c5290592-d347-44d9-aea1-8fe5f3c8f9cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in climbing-detection-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31510/31510 [00:00<00:00, 31544.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to climbing-detection-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1036/1036 [00:00<00:00, 6067.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"min-tang-ugcdi\").project(\"climbing-detection\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 561031,
     "status": "ok",
     "timestamp": 1717348536799,
     "user": {
      "displayName": "Adithya Balagoni",
      "userId": "17243942917959406159"
     },
     "user_tz": -330
    },
    "id": "1rb5ZZru4-cH",
    "outputId": "91900067-8a0e-47f2-91ca-502591836f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/climbing-detection-1/data.yaml, epochs=40, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train10\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train10', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/climbing-detection-1/train/labels.cache... 488 images, 0 backgrounds, 0 corrupt: 100% 488/488 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/climbing-detection-1/valid/labels.cache... 19 images, 0 backgrounds, 0 corrupt: 100% 19/19 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train10/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train10\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/40      4.22G      1.763      3.118      2.038         14        640: 100% 31/31 [00:15<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.38it/s]\n",
      "                   all         19         23      0.398      0.478       0.36      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/40      4.13G       1.78      1.814      1.998         27        640: 100% 31/31 [00:09<00:00,  3.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.12it/s]\n",
      "                   all         19         23      0.081      0.565     0.0614     0.0172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/40      4.14G       1.85      1.885      2.015         17        640: 100% 31/31 [00:13<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.68it/s]\n",
      "                   all         19         23       0.25      0.174      0.134       0.02\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/40      4.15G      1.853      1.924      2.025         16        640: 100% 31/31 [00:10<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.87it/s]\n",
      "                   all         19         23     0.0107     0.0435    0.00231   0.000427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/40      4.27G      1.862      1.856      2.056         17        640: 100% 31/31 [00:09<00:00,  3.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.82it/s]\n",
      "                   all         19         23     0.0271     0.0633      0.011    0.00297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/40      4.14G       1.84      1.865      2.012         17        640: 100% 31/31 [00:13<00:00,  2.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.96it/s]\n",
      "                   all         19         23      0.134      0.217     0.0574     0.0122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/40      4.13G      1.769      1.745      1.939         22        640: 100% 31/31 [00:10<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.27it/s]\n",
      "                   all         19         23      0.249      0.261      0.269     0.0628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/40      4.14G      1.776       1.81      1.969         15        640: 100% 31/31 [00:10<00:00,  2.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.47it/s]\n",
      "                   all         19         23      0.163      0.348      0.153     0.0505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/40      4.11G       1.76      1.701      1.953         28        640: 100% 31/31 [00:12<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.54it/s]\n",
      "                   all         19         23      0.241      0.304      0.218     0.0571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/40      4.14G      1.718      1.667      1.893         23        640: 100% 31/31 [00:09<00:00,  3.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.19it/s]\n",
      "                   all         19         23      0.531      0.565      0.467      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/40      4.14G       1.66      1.577      1.871         23        640: 100% 31/31 [00:11<00:00,  2.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.72it/s]\n",
      "                   all         19         23      0.605      0.478      0.469      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/40      4.14G      1.721      1.587      1.906         20        640: 100% 31/31 [00:12<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.90it/s]\n",
      "                   all         19         23      0.294      0.522      0.248     0.0589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/40      4.27G      1.658      1.643      1.877         21        640: 100% 31/31 [00:09<00:00,  3.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.56it/s]\n",
      "                   all         19         23      0.452      0.609      0.572      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/40      4.14G       1.57      1.484        1.8         19        640: 100% 31/31 [00:12<00:00,  2.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.05it/s]\n",
      "                   all         19         23      0.493      0.435      0.341     0.0661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/40      4.14G      1.607      1.489      1.808         22        640: 100% 31/31 [00:12<00:00,  2.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.12it/s]\n",
      "                   all         19         23      0.754      0.522      0.617       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/40      4.13G       1.57      1.468       1.79         18        640: 100% 31/31 [00:09<00:00,  3.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.67it/s]\n",
      "                   all         19         23      0.533      0.826      0.691      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/40      4.27G      1.554       1.39       1.76         20        640: 100% 31/31 [00:12<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.59it/s]\n",
      "                   all         19         23      0.633      0.696      0.715      0.275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/40      4.15G      1.584      1.417      1.769         24        640: 100% 31/31 [00:11<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.04it/s]\n",
      "                   all         19         23      0.629      0.442       0.54      0.148\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/40      4.14G      1.528      1.377      1.703         25        640: 100% 31/31 [00:09<00:00,  3.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.97it/s]\n",
      "                   all         19         23      0.798      0.688       0.77      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/40      4.14G      1.501      1.336      1.704         22        640: 100% 31/31 [00:13<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.48it/s]\n",
      "                   all         19         23      0.786      0.637      0.737      0.307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/40      4.11G      1.477      1.285      1.717         21        640: 100% 31/31 [00:11<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.89it/s]\n",
      "                   all         19         23      0.706      0.826      0.795      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/40      4.14G       1.46      1.253      1.691         23        640: 100% 31/31 [00:09<00:00,  3.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.50it/s]\n",
      "                   all         19         23      0.696      0.696      0.734      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/40      4.14G      1.412      1.182      1.628         22        640: 100% 31/31 [00:13<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.38it/s]\n",
      "                   all         19         23       0.78      0.652      0.797      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/40      4.14G      1.423      1.223      1.664         20        640: 100% 31/31 [00:10<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.69it/s]\n",
      "                   all         19         23      0.871      0.696      0.843      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/40      4.11G      1.403      1.169      1.643         18        640: 100% 31/31 [00:10<00:00,  2.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.10it/s]\n",
      "                   all         19         23      0.698      0.803      0.775      0.363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/40      4.15G      1.351      1.133      1.606         17        640: 100% 31/31 [00:13<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.66it/s]\n",
      "                   all         19         23      0.662      0.683      0.711      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/40      4.13G       1.36      1.121      1.586         18        640: 100% 31/31 [00:09<00:00,  3.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.05it/s]\n",
      "                   all         19         23      0.719      0.557      0.686      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/40      4.13G      1.338      1.088      1.574         17        640: 100% 31/31 [00:11<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.08it/s]\n",
      "                   all         19         23      0.684      0.739      0.761      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/40      4.12G      1.312      1.071      1.545         20        640: 100% 31/31 [00:12<00:00,  2.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.77it/s]\n",
      "                   all         19         23      0.776      0.752      0.808      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/40      4.14G      1.302      1.081      1.548         20        640: 100% 31/31 [00:09<00:00,  3.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.29it/s]\n",
      "                   all         19         23      0.769      0.725      0.805      0.359\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/40      4.14G       1.26     0.8862      1.621          9        640: 100% 31/31 [00:13<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.36it/s]\n",
      "                   all         19         23      0.807      0.609      0.766      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/40      4.14G       1.22     0.7743      1.601         10        640: 100% 31/31 [00:12<00:00,  2.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.68it/s]\n",
      "                   all         19         23      0.618      0.844       0.76      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/40      4.12G      1.191     0.7364      1.571         10        640: 100% 31/31 [00:08<00:00,  3.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.30it/s]\n",
      "                   all         19         23       0.83      0.652      0.766      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/40      4.14G      1.152     0.7254      1.534         11        640: 100% 31/31 [00:12<00:00,  2.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.10it/s]\n",
      "                   all         19         23      0.728      0.813      0.797      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/40      4.14G      1.131     0.6738      1.515          9        640: 100% 31/31 [00:11<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.23it/s]\n",
      "                   all         19         23      0.798      0.739      0.807      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/40      4.13G      1.124     0.6727      1.529          8        640: 100% 31/31 [00:08<00:00,  3.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.53it/s]\n",
      "                   all         19         23      0.671       0.87      0.836      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/40      4.27G      1.081     0.6487      1.463          8        640: 100% 31/31 [00:13<00:00,  2.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.65it/s]\n",
      "                   all         19         23      0.835       0.66      0.819      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/40      4.15G      1.034     0.6453      1.447          8        640: 100% 31/31 [00:09<00:00,  3.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.47it/s]\n",
      "                   all         19         23      0.736       0.85      0.856      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/40      4.13G      1.041     0.6224      1.439         14        640: 100% 31/31 [00:11<00:00,  2.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.79it/s]\n",
      "                   all         19         23      0.658       0.87      0.803      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/40      4.14G      1.007     0.6034      1.419          8        640: 100% 31/31 [00:11<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.12it/s]\n",
      "                   all         19         23      0.667      0.869      0.818      0.441\n",
      "\n",
      "40 epochs completed in 0.149 hours.\n",
      "Optimizer stripped from runs/detect/train10/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train10/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train10/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.27 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.98it/s]\n",
      "                   all         19         23      0.728      0.814      0.797      0.455\n",
      "Speed: 0.2ms preprocess, 5.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train10\u001b[0m\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=40 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7691,
     "status": "ok",
     "timestamp": 1717393205929,
     "user": {
      "displayName": "afith 234",
      "userId": "04481233657332223077"
     },
     "user_tz": -330
    },
    "id": "Hqqm2LXs5Z7D",
    "outputId": "2b159b74-5952-44aa-e639-427c1fde4f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.28, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in firesmoke-3 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58482/58482 [00:01<00:00, 57904.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to firesmoke-3 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3556/3556 [00:00<00:00, 7233.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4BYHUEf3y6ScgswahwiP\")\n",
    "project = rf.workspace(\"gradproject-b3qu8\").project(\"firesmoke-qedaj\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1105376,
     "status": "ok",
     "timestamp": 1717394442315,
     "user": {
      "displayName": "afith 234",
      "userId": "04481233657332223077"
     },
     "user_tz": -330
    },
    "id": "dPY7EBX5ghgy",
    "outputId": "f1b0e451-0ade-4984-dcaa-078f38efe601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/datasets/firesmoke-3/data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
      "100% 755k/755k [00:00<00:00, 23.0MB/s]\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11136374 parameters, 11136358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "100% 6.23M/6.23M [00:00<00:00, 130MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/firesmoke-3/train/labels... 1244 images, 0 backgrounds, 0 corrupt: 100% 1244/1244 [00:00<00:00, 2058.64it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/firesmoke-3/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/firesmoke-3/valid/labels... 357 images, 0 backgrounds, 0 corrupt: 100% 357/357 [00:00<00:00, 1274.75it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/firesmoke-3/valid/labels.cache\n",
      "Plotting labels to runs/detect/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/30      4.26G      2.088      2.957      2.057         76        640: 100% 78/78 [00:38<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:05<00:00,  2.24it/s]\n",
      "                   all        357        703      0.249      0.217      0.154     0.0474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/30      4.17G      2.138      2.529      2.104         43        640: 100% 78/78 [00:31<00:00,  2.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.88it/s]\n",
      "                   all        357        703       0.11      0.117     0.0387     0.0109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/30      4.19G      2.137      2.544      2.109         40        640: 100% 78/78 [00:29<00:00,  2.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:05<00:00,  2.28it/s]\n",
      "                   all        357        703      0.203       0.18      0.131     0.0407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/30      4.16G      2.095       2.51      2.082         36        640: 100% 78/78 [00:27<00:00,  2.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.78it/s]\n",
      "                   all        357        703      0.504      0.199      0.205      0.074\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/30      4.17G      2.065      2.426      2.029         46        640: 100% 78/78 [00:26<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:05<00:00,  2.16it/s]\n",
      "                   all        357        703      0.286      0.364       0.26     0.0958\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/30      4.16G      2.023      2.343      2.008         52        640: 100% 78/78 [00:28<00:00,  2.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.71it/s]\n",
      "                   all        357        703      0.351       0.36      0.318      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/30      4.16G      2.004      2.303      1.999         39        640: 100% 78/78 [00:29<00:00,  2.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.59it/s]\n",
      "                   all        357        703      0.486      0.344      0.359       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/30      4.13G       1.96      2.236      1.961         47        640: 100% 78/78 [00:31<00:00,  2.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:03<00:00,  3.03it/s]\n",
      "                   all        357        703      0.448      0.424      0.385      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/30      4.22G      1.978      2.251      1.962         55        640: 100% 78/78 [00:30<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.85it/s]\n",
      "                   all        357        703       0.38      0.384      0.317      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/30      4.16G      1.944      2.171      1.939         63        640: 100% 78/78 [00:28<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.94it/s]\n",
      "                   all        357        703      0.515      0.437      0.431      0.177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/30      4.16G      1.904      2.091      1.906         56        640: 100% 78/78 [00:26<00:00,  2.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.95it/s]\n",
      "                   all        357        703      0.513      0.484      0.476      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/30      4.16G      1.921      2.096      1.907         39        640: 100% 78/78 [00:26<00:00,  2.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.65it/s]\n",
      "                   all        357        703      0.447      0.495      0.458      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/30      4.19G      1.865      1.998      1.864         38        640: 100% 78/78 [00:28<00:00,  2.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:03<00:00,  3.11it/s]\n",
      "                   all        357        703      0.572      0.495      0.514      0.218\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/30      4.16G      1.844      2.008      1.876         55        640: 100% 78/78 [00:31<00:00,  2.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.80it/s]\n",
      "                   all        357        703       0.45      0.481      0.445      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/30      4.19G       1.83      1.931      1.837         40        640: 100% 78/78 [00:28<00:00,  2.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.99it/s]\n",
      "                   all        357        703      0.597      0.497      0.534       0.23\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/30      4.15G      1.831      1.915      1.847         31        640: 100% 78/78 [00:29<00:00,  2.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.95it/s]\n",
      "                   all        357        703      0.597      0.475      0.513      0.215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/30      4.18G      1.797      1.941      1.836         33        640: 100% 78/78 [00:29<00:00,  2.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.59it/s]\n",
      "                   all        357        703      0.579      0.524      0.534      0.228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/30      4.16G      1.802      1.835        1.8         29        640: 100% 78/78 [00:27<00:00,  2.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.76it/s]\n",
      "                   all        357        703      0.685      0.522      0.581      0.255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/30      4.19G       1.78      1.817      1.818         42        640: 100% 78/78 [00:26<00:00,  2.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:05<00:00,  2.07it/s]\n",
      "                   all        357        703       0.62       0.55      0.563      0.248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/30      4.17G      1.739      1.756      1.766         28        640: 100% 78/78 [00:27<00:00,  2.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.91it/s]\n",
      "                   all        357        703      0.692      0.554      0.603      0.267\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/30      4.17G      1.811      1.757      1.873         15        640: 100% 78/78 [00:31<00:00,  2.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.93it/s]\n",
      "                   all        357        703      0.659      0.559      0.607      0.272\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/30      4.15G      1.798      1.683       1.85         18        640: 100% 78/78 [00:25<00:00,  3.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.84it/s]\n",
      "                   all        357        703      0.634      0.587      0.602      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/30      4.16G      1.742      1.601       1.82         20        640: 100% 78/78 [00:27<00:00,  2.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:03<00:00,  3.21it/s]\n",
      "                   all        357        703       0.67      0.596       0.63      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/30      4.16G      1.721       1.58       1.82         20        640: 100% 78/78 [00:28<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:04<00:00,  2.48it/s]\n",
      "                   all        357        703      0.696      0.609      0.638      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/30      4.16G      1.685      1.516      1.787         28        640: 100% 78/78 [00:25<00:00,  3.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.80it/s]\n",
      "                   all        357        703      0.736      0.586      0.635      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/30      4.13G      1.679      1.468      1.765         27        640: 100% 78/78 [00:27<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:05<00:00,  2.04it/s]\n",
      "                   all        357        703      0.699      0.608      0.646      0.305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/30      4.15G      1.649      1.437       1.75         17        640: 100% 78/78 [00:28<00:00,  2.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:03<00:00,  3.11it/s]\n",
      "                   all        357        703      0.721      0.613       0.66      0.303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/30      4.14G      1.595      1.369      1.703         22        640: 100% 78/78 [00:30<00:00,  2.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:07<00:00,  1.71it/s]\n",
      "                   all        357        703      0.712      0.606      0.663      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/30      4.15G      1.601       1.36      1.715         24        640: 100% 78/78 [00:26<00:00,  2.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.92it/s]\n",
      "                   all        357        703      0.746       0.62       0.68      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/30      4.13G      1.593      1.312      1.697         29        640: 100% 78/78 [00:27<00:00,  2.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:06<00:00,  1.93it/s]\n",
      "                   all        357        703      0.788      0.623       0.69      0.328\n",
      "\n",
      "30 epochs completed in 0.296 hours.\n",
      "Optimizer stripped from runs/detect/train3/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/detect/train3/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/detect/train3/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.28 ğŸš€ Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:07<00:00,  1.51it/s]\n",
      "                   all        357        703      0.768      0.637      0.691      0.328\n",
      "                  fire        264        342      0.804      0.787      0.825      0.415\n",
      "                 smoke        221        361      0.732      0.488      0.557       0.24\n",
      "Speed: 0.4ms preprocess, 5.6ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
      "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# !yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=30 imgsz=640 plots=True\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data=f'{dataset.location}/data.yaml',  # Path to the dataset YAML file\n",
    "    epochs=10,                             # Number of training epochs\n",
    "    imgsz=512,                             # Image size for training\n",
    "    plots=True                             # Enable training plots\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XwRjxRKsr6fx"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Set ENV Variables (place before imports)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# reduce CPU utilization during training\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplorer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Explorer\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NAS, RTDETR, SAM, YOLO, FastSAM, YOLOWorld\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASSETS, SETTINGS\n",
      "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO ğŸš€, AGPL-3.0 license\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dataloader, build_grounding, build_yolo_dataset, load_inference_source\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     ClassificationDataset,\n\u001b[0;32m      7\u001b[0m     GroundingDataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     YOLOMultiModalDataset,\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsutil\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FORMATS_HELP_MSG, HELP_URL, IMG_FORMATS\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_CFG, LOCAL_RANK, LOGGER, NUM_THREADS, TQDM\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def predict_accident(image_url):\n",
    "    # Load the trained model\n",
    "    model = YOLO('./realtime_accident.pt')\n",
    "    \n",
    "    # Fetch the image from the URL\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    \n",
    "    # Perform prediction\n",
    "    results = model(img)\n",
    "    \n",
    "    # Display or return results\n",
    "    results.show()  # This will display the image with predictions\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "image_url = 'https://valleycollision.com/blog/the-top-5-causes-of-car-accidents-in-the-u-s/'\n",
    "predict_accident(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi==0.108.0\n",
      "  Using cached fastapi-0.108.0-py3-none-any.whl (92 kB)\n",
      "Requirement already satisfied: uvicorn[standard] in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 2)) (0.30.6)\n",
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.38-py3-none-any.whl (896 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Collecting keras\n",
      "  Using cached keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 7)) (2.32.3)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.35.71-py3-none-any.whl (139 kB)\n",
      "Collecting dnspython\n",
      "  Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Requirement already satisfied: python-decouple in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 10)) (3.8)\n",
      "Collecting face-recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting python-multipart\n",
      "  Using cached python_multipart-0.0.17-py3-none-any.whl (24 kB)\n",
      "Collecting roboflow\n",
      "  Using cached roboflow-1.1.49-py3-none-any.whl (80 kB)\n",
      "Collecting inference-sdk\n",
      "  Using cached inference_sdk-0.28.2-py3-none-any.whl (33 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi==0.108.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi==0.108.0->-r requirements.txt (line 1)) (2.9.2)\n",
      "Collecting starlette<0.33.0,>=0.29.0\n",
      "  Using cached starlette-0.32.0.post1-py3-none-any.whl (70 kB)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (0.4.6)\n",
      "Collecting websockets>=10.4\n",
      "  Using cached websockets-14.1-cp310-cp310-win_amd64.whl (163 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (6.0.2)\n",
      "Collecting httptools>=0.5.0\n",
      "  Using cached httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]->-r requirements.txt (line 2)) (1.0.1)\n",
      "Collecting watchfiles>=0.13\n",
      "  Using cached watchfiles-1.0.0-cp310-none-win_amd64.whl (285 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (4.66.5)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (9.0.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (10.4.0)\n",
      "Requirement already satisfied: torch!=2.4.0,>=1.8.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (2.5.1)\n",
      "Collecting matplotlib>=3.3.0\n",
      "  Using cached matplotlib-3.9.2-cp310-cp310-win_amd64.whl (7.8 MB)\n",
      "Requirement already satisfied: psutil in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (5.9.3)\n",
      "Collecting ultralytics-thop>=2.0.0\n",
      "  Using cached ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (0.20.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (1.14.1)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics->-r requirements.txt (line 3)) (1.4.3)\n",
      "Collecting h5py\n",
      "  Using cached h5py-3.12.1-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "Requirement already satisfied: rich in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->-r requirements.txt (line 5)) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->-r requirements.txt (line 5)) (0.0.8)\n",
      "Requirement already satisfied: absl-py in c:\\users\\adith\\appdata\\roaming\\python\\python310\\site-packages (from keras->-r requirements.txt (line 5)) (1.4.0)\n",
      "Collecting optree\n",
      "  Using cached optree-0.13.1-cp310-cp310-win_amd64.whl (282 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras->-r requirements.txt (line 5)) (24.2)\n",
      "Collecting ml-dtypes\n",
      "  Using cached ml_dtypes-0.5.0-cp310-cp310-win_amd64.whl (211 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->-r requirements.txt (line 7)) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->-r requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->-r requirements.txt (line 7)) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->-r requirements.txt (line 7)) (1.26.10)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0\n",
      "  Using cached s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
      "Collecting botocore<1.36.0,>=1.35.71\n",
      "  Using cached botocore-1.35.71-py3-none-any.whl (13.0 MB)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from face-recognition->-r requirements.txt (line 11)) (0.3.0)\n",
      "Collecting dlib>=19.7\n",
      "  Using cached dlib-19.24.6.tar.gz (3.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting cycler\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow->-r requirements.txt (line 13)) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow->-r requirements.txt (line 13)) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow->-r requirements.txt (line 13)) (1.16.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow->-r requirements.txt (line 13)) (1.2.0)\n",
      "Collecting opencv-python-headless==4.10.0.84\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.7-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting dataclasses-json~=0.6.0\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: aiohttp<=3.10.11,>=3.9.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from inference-sdk->-r requirements.txt (line 14)) (3.10.6)\n",
      "Collecting supervision<=0.22.0,>=0.21.0\n",
      "  Using cached supervision-0.22.0-py3-none-any.whl (135 kB)\n",
      "Collecting backoff~=2.2.0\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting tensorflow-intel==2.18.0\n",
      "  Using cached tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (18.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (58.1.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (1.66.1)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting ml-dtypes\n",
      "  Using cached ml_dtypes-0.4.1-cp310-cp310-win_amd64.whl (126 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (24.3.25)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (3.20.3)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.17.0-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (6.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (22.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (2.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<=3.10.11,>=3.9.0->inference-sdk->-r requirements.txt (line 14)) (1.12.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json~=0.6.0->inference-sdk->-r requirements.txt (line 14)) (3.22.0)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 3)) (3.0.9)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.55.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 3)) (2022.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.108.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.108.0->-r requirements.txt (line 1)) (2.23.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from starlette<0.33.0,>=0.29.0->fastapi==0.108.0->-r requirements.txt (line 1)) (3.6.2)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from supervision<=0.22.0,>=0.21.0->inference-sdk->-r requirements.txt (line 14)) (0.7.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (2024.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (3.16.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras->-r requirements.txt (line 5)) (2.13.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi==0.108.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 15)) (0.37.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->-r requirements.txt (line 5)) (0.1.2)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch!=2.4.0,>=1.8.0->ultralytics->-r requirements.txt (line 3)) (2.1.1)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py): started\n",
      "  Building wheel for dlib (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for dlib\n",
      "Failed to build dlib\n",
      "Installing collected packages: dlib, wrapt, werkzeug, websockets, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, python-multipart, optree, opt-einsum, opencv-python-headless, opencv-python, mypy-extensions, ml-dtypes, markdown, kiwisolver, jmespath, idna, httptools, h5py, google-pasta, gast, fonttools, dnspython, cycler, contourpy, backoff, astunparse, typing-inspect, tensorboard, matplotlib, face-recognition, botocore, watchfiles, ultralytics-thop, supervision, starlette, seaborn, s3transfer, keras, dataclasses-json, ultralytics, tensorflow-intel, roboflow, inference-sdk, fastapi, boto3, tensorflow\n",
      "  Running setup.py install for dlib: started\n",
      "  Running setup.py install for dlib: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— python setup.py bdist_wheel did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [41 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_ext\n",
      "      \n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      \n",
      "                         CMake is not installed on your system!\n",
      "      \n",
      "          Or it is possible some broken copy of cmake is installed on your system.\n",
      "          It is unfortunately very common for python package managers to include\n",
      "          broken copies of cmake.  So if the error above this refers to some file\n",
      "          path to a cmake file inside a python or anaconda or miniconda path then you\n",
      "          should delete that broken copy of cmake from your computer.\n",
      "      \n",
      "          Instead, please get an official copy of cmake from one of these known good\n",
      "          sources of an official cmake:\n",
      "              - cmake.org (this is how windows users should get cmake)\n",
      "              - apt install cmake (for Ubuntu or Debian based systems)\n",
      "              - yum install cmake (for Redhat or CenOS based systems)\n",
      "      \n",
      "          On a linux machine you can run `which cmake` to see what cmake you are\n",
      "          actually using.  If it tells you it's some cmake from any kind of python\n",
      "          packager delete it and install an official cmake.\n",
      "      \n",
      "          More generally, cmake is not installed if when you open a terminal window\n",
      "          and type\n",
      "             cmake --version\n",
      "          you get an error.  So you can use that as a very basic test to see if you\n",
      "          have cmake installed.  That is, if cmake --version doesn't run from the\n",
      "          same terminal window from which you are reading this error message, then\n",
      "          you have not installed cmake.  Windows users should take note that they\n",
      "          need to tell the cmake installer to add cmake to their PATH.  Since you\n",
      "          can't run commands that are not in your PATH.  This is how the PATH works\n",
      "          on Linux as well, but failing to add cmake to the PATH is a particularly\n",
      "          common problem on windows and rarely a problem on Linux.\n",
      "      \n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for dlib\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— Running setup.py install for dlib did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [41 lines of output]\n",
      "      running install\n",
      "      running build\n",
      "      running build_ext\n",
      "      \n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      \n",
      "                         CMake is not installed on your system!\n",
      "      \n",
      "          Or it is possible some broken copy of cmake is installed on your system.\n",
      "          It is unfortunately very common for python package managers to include\n",
      "          broken copies of cmake.  So if the error above this refers to some file\n",
      "          path to a cmake file inside a python or anaconda or miniconda path then you\n",
      "          should delete that broken copy of cmake from your computer.\n",
      "      \n",
      "          Instead, please get an official copy of cmake from one of these known good\n",
      "          sources of an official cmake:\n",
      "              - cmake.org (this is how windows users should get cmake)\n",
      "              - apt install cmake (for Ubuntu or Debian based systems)\n",
      "              - yum install cmake (for Redhat or CenOS based systems)\n",
      "      \n",
      "          On a linux machine you can run `which cmake` to see what cmake you are\n",
      "          actually using.  If it tells you it's some cmake from any kind of python\n",
      "          packager delete it and install an official cmake.\n",
      "      \n",
      "          More generally, cmake is not installed if when you open a terminal window\n",
      "          and type\n",
      "             cmake --version\n",
      "          you get an error.  So you can use that as a very basic test to see if you\n",
      "          have cmake installed.  That is, if cmake --version doesn't run from the\n",
      "          same terminal window from which you are reading this error message, then\n",
      "          you have not installed cmake.  Windows users should take note that they\n",
      "          need to tell the cmake installer to add cmake to their PATH.  Since you\n",
      "          can't run commands that are not in your PATH.  This is how the PATH works\n",
      "          on Linux as well, but failing to add cmake to the PATH is a particularly\n",
      "          common problem on windows and rarely a problem on Linux.\n",
      "      \n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      ================================================================================\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Ã— Encountered error while trying to install package.\n",
      "â•°â”€> dlib\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\adith\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install requests ultralytics Pillow pytorch\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.5.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: c:\\users\\adith\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: sentence-transformers, torchvision\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1uQeR0jUZRP_4XUg9UbNhW1xx1mH-qkWg",
     "timestamp": 1717395459592
    },
    {
     "file_id": "1hmpdjZqDISgAMSwJzQDw-Jnkd0p-kTBa",
     "timestamp": 1717392966099
    },
    {
     "file_id": "1Ek41jF2Zo52jQFUJWwau3Cih6YMP-kmY",
     "timestamp": 1717348967197
    },
    {
     "file_id": "1TvAif6jTpS48FVcC2zZ5CkWQpc3mv9x-",
     "timestamp": 1717335972981
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
